{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[this demo requires doom installed either from gym-pool or from [ppaquette's repo](https://github.com/ppaquette/gym-doom)]\n",
    "\n",
    "## Basic Doom demo\n",
    "\n",
    "This demo solves DoomBasic env with a simple q-learning with experience replay.\n",
    "\n",
    "Video observation forces you to use ```CNN```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=gpu,floatX=float32\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%env THEANO_FLAGS=device=gpu,floatX=float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "[2017-03-18 22:22:45,784] The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GT 730M (CNMeM is enabled with initial size: 70.0% of memory, cuDNN 5004)\n",
      "[2017-03-18 22:22:50,552] Making new env: ppaquette/DoomBasic-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ppaquette_gym_doom\n",
    "from gym.wrappers import SkipWrapper\n",
    "from ppaquette_gym_doom.wrappers.action_space import ToDiscrete\n",
    "from agentnet.experiments.openai_gym.wrappers import PreprocessImage\n",
    "GAME_NAME = 'ppaquette/DoomBasic-v0'\n",
    "\n",
    "make_env = lambda: PreprocessImage(SkipWrapper(4)(ToDiscrete(\"minimal\")(gym.make(GAME_NAME))),\n",
    "                                   width=48,height=48,grayscale=True)\n",
    "\n",
    "env = make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#global params.\n",
    "observation_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "#number of parallel agents and batch sequence length (frames)\n",
    "SEQ_LENGTH = 3\n",
    "FRAME_NUMBER = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.0 False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2f7007a908>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD+CAYAAAAalrhRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnWuMXtV1ht/lQLDjCx48njH2+IKNTbGNjQ1BKU5NoJA6\nTRQICSQkqiBNlD+VCOolAaSofxBqG0VVokr5kUJEUNomJkntSmlNCaGIcLXBNy7G48Fjc5mx4zsO\n4RJ2f8w39py132++5bHn84z2+0hI3pt9zllnn7PmzH5nrbUtpQQhRFmMOd0GCCGajxxfiAKR4wtR\nIHJ8IQpEji9EgcjxhSiQk3J8M1tlZi+Z2ctm9s1TZZQQYnixof4d38zGAHgZwJ8CeB3AMwC+kFJ6\n6dSZJ4QYDk7mi38ZgO0ppe6U0rsA/gPAtafGLCHEcHLGSRw7A8DuAe1X0ffDoIKZKTRQiNNESslY\n/8k4fpiPfvSj6O7uxuzZs8PHnHXWWVnf22+/XWmzZcof/vCHrO+MM6q3yY7z5x47duyxf/fbHrme\nv1YUs/z5RJZh48ePz/qOHj0KAJU5j5wrYoOfJ6A6V/WOe/fdd7MxH/zgB+vacqLvS4QJEyZU2m++\n+eYpO3f//e7atQuzZs0CMPg75Y8bSOS4CI899ljd/3cyjv8agFkD2h21vozu7m4cOnQI3d3dOPvs\nszF58uSTuKwQgnHw4EEcOnQoNPZkHP8ZAOeb2WwAbwD4AoCb2MDZs2cPy09wIcRxJk+eXPmo7t69\nu+7YIav6QN+f8wB8F30i4T0ppX8gY1JrayveeeedY7/aLV26tDJm06ZNoestXry40t66deuwHTdv\n3rxj/z58+DAmTZqEHTt2nNBx/USOmzt3btbX1dXV8LiZM2dmff0PfOCce2bMmJH17du3L+v7/e9/\nf0qOO/fcc7Mx/uv0u9/97ti/+20/0eP6mTJlStbnYXb75QCQLzsHO+6tt97CuHHjAACTJk2qjHn9\n9ddD14scd+aZZ2Z9/tmsX79+eNb4KaX/AXBBZOxg67mRjn8Qo4XRPOej1fZ+px/pKHJPiAKR4wtR\nIHJ8IQrkpMS90AXM0oIFCyp977//fqXNhJiDBw9mfe+9916lPX369GzMnj17Gtp03nnnZX2vvPJK\nw+OY0OSVUya6nHPOOVnfb3/720p7zJj8ZzCLZfCiGfvbO1sf+78Ns3gD9rd2D7u/yHFTp07N+vbu\n3Vtps3uZM2dO1rdz586G12PPuLOzs9L+wAc+kI1pbW3N+vyzYpx99tlZ3+HDhytt5mvsb/SReBWG\njynp7OysK+7piy9EgcjxhSgQOb4QBSLHF6JAmpKks3///kq7P4mhHxbZxsSSt956q9J+8cUXszEs\nLLi7u7vSZpFXkeg+fx9ALloxcZGJdF689IIns6meXZ758+dnfT76i0WMsQQnP+dsfnt7exvaxCIT\nt23b1vA4Nnf++bW3t2djNm/enPW98847lTabp4hN0efibY/cC5D7x65duxraBACLFi2qtL2YORB9\n8YUoEDm+EAUixxeiQJoSwLN8+fJKnw8eYYExLKAmUpCArVP9cT4Ihtk01Hlhx7H1u69JcOTIkWwM\nC2iJBMsMlrHXDwvgidjOAnGYruHPHynywYKDvMbAzv2hD30oG8My9iKw+fVZb2+88UY2hgUD+YAz\nNgdsPv26nx0XKTjz1FNPKYBHCHEcOb4QBSLHF6JA5PhCFEhTAnh8AMKll15aaf/mN7/JjmEBJj5L\nygdkALz0lQ/KYMEkkfJYLBvQB8Zccskl2ZgNGzZkfUwg8rD780En27dvb3geIBYEErk/FljFzh2p\noOPv74IL8mJO7NxevIyWYPP3x0paLVmyJOt78sknK20mjLI+LyIvW7YsG7N+/fqsz2ersiAfRkdH\nR2gcoC++EEUixxeiQOT4QhRIUwJ4/LrJB3wMtfoMC1R59dVXsz5/fZbA4ddVLCiFBWn4oBO2Lmdr\nZ7/G97oHwNd/LS0tlTarDhPZzYcFFbFKQQcOHKi0fTAWADz77LMN7WTrVP/c2XvAAlXa2toqbV/J\nB4hpLSx4hiUc+XeR7SbE8MlDzE6mKfj3c9q0adkYpk/4QKauri4F8AghjiPHF6JA5PhCFIgcX4gC\naYq4t2rVqkqfz4CKbhHthTSWScWELX9+Jhj5MUzAYef252ICIDvOZ26xgBcmFEbmYKhbbkdgAhwT\nCn0AFptPfy4/J/X6/P2xMZEy4Oy5RO4vWmL8dD+rX/3qVxL3hBDHkeMLUSByfCEKRI4vRIE0JTvP\nR9x5AYWJbUwki4iCkZJETGTx5bnYuZkY5IWfqE0R4WfixIlZnxfJWLQdK+Plz+Uj8gCeEfnmm29W\n2lHh6ejRo5U2E+D8M2Zzx4RD/6wizxzIbWfvGLueJyJUsnFMFGTHebvY3LFndejQodzYOuiLL0SB\nyPGFKBA5vhAF0pQ1vl+z+PUfK4/MiGRFRUpws/La/ji29vJ2MyL6AZBvocUyxSL7srPrsfvz6362\nvmV9vrw1W4dHMinZOtWvw1l1H3Yv/j1g5/baBLsee59YIJVf97Pnya7nYVoE0xT8u8cCudhzYHNV\nD33xhSgQOb4QBdLQ8c3sHjPrNbPNA/pazOxBM9tmZuvMLP8dTQgxYol88X8I4M9c3+0AHkopXQDg\nYQB3nGrDhBDDR0NxL6X0mJn5TdGvBXBF7d/3AXgEfT8MKF6s8IEMrNwR62ttba20WaAKE2x82Wa2\nb7gXtnzpKICLbX7fv0jZbABYunRppf3EE09kY1gQyvjx4yttFrTByod3dXU1tImVt/alyVngCBOo\n/N517NwvvfRSQ5tmz/avXn6c39sOAHp6erI+L65Fyl4B+bvBhFh2PW+7378Q4HO3ePHiSpu9r0wI\nZQFC9RjqGr8tpdQLACmlHgBtDcYLIUYQp+rPeYPGcQ7crKKlpSX85zshRJyjR4+GdwkequP3mll7\nSqnXzKYByEvSDsDvbnMif28UQsQYP358ZSk42A480V/1rfZfP2sB3FL7980A1pyQhUKI00rD0ltm\n9m8APgZgCoBeAH8P4D8BrAYwE0A3gBtTSgfrHJ9WrlxZ6fNffCbIMRHJR6kx21nEnRfJ2K9D/jgm\nnvhoO3Yci2KLlFyaPHlyNoZl0EVKfbF5YVFjHma7jxpj8xutT+/x+yIw8YvhMxL379+fjWFz4N8D\nJqyxiDgPi+5jz9jPOZsnZru3i/nCxo0bsz7/Du3cubNu6a2Iqv/FOv/r6kbHCiFGJorcE6JA5PhC\nFEhTsvN8kInf344FaTDl32fHsfUt22fMr83HjRuXjfHrtsOHD2djIus/VhEnst5lgTgsIGPSpEmV\nNssYZOtNvzZn+/mx/dg8bF3MbPd/svVZfux6bH5nzZqV9fn5jJQvZzYxIll2TJPygVxAHtTDNCKm\nq+zatavSZnoF64v+KQ/QF1+IIpHjC1EgcnwhCkSOL0SBNGXvPJ8F5cU1FhDBBDEvLDFxL7KvGQvO\n8cEjTAhix3mYqMREnUipcIafgylTpmRjWDCQF/d27tzZ0CZmV9RO/0zb2vI8Li9UMnGRzZ2fAxZU\nxPAiIBNi2bvonymzacGCBVmfvx8mGLN58e8+E0aZmOjnZcuWLdo7TwhxHDm+EAUixxeiQOT4QhRI\nUyL3PF5Q3Lt3bzbGl5gCcuGOCU2sPFajuv5AXq6KiYQsQs1nYLEa6CxSkPUNBZZ1N1gedj/RYij+\nWQ11nzqWheZFMnYeVgLNj2MiLzuXHxfJ5ATyZ8reDSZMejEvGlnn/YGVLYvs1TcY+uILUSByfCEK\nRI4vRIE0ZY3vK4j4NXYkuwvI11osU4ytv3wGFFvH+XUx0xjYOtVnA7Lrs0ARv9577bXXsjHMBh+4\nwYJCmM4QCT5ia2WfJcl0lch6kwUH+WfMngvD28CuzwLA/Byw4DUWLOOvxzL42LxMnDix4fXYux8J\nmmLZq8z2euiLL0SByPGFKBA5vhAFIscXokCaIu75jCcvkkWCdYA8S4ploQ3ctafe+Zmg4gUiJsQw\nkc4HWzCxbc+efL8RLzgy4ZCV1/aBImyemEjnxUuWRchEsrFjx1bavmwawMtHRUqERcpIsz5f0oq9\nB0zo8vsaMnGY7Tvo59PfG8DnzousLKuPXc8Hd7H5Zc+YCcT10BdfiAKR4wtRIHJ8IQpEji9EgTSl\n9Nby5csrfT6qi2UVMQHFR38xMYPtTxa5xzlz5lTa3d3d2ZgjR440vB4T91g5Jx+1xsQhJuD47Dh2\nb0xEam1tzfoanZvZsG3btmwM2xfBR5tFBDE2dyziz4tdXoAEYuXO2JwwkdWfnz0rdj0vvLKIPxZl\n6SP+2NwxcdYLmjt27FDpLSHEceT4QhSIHF+IAmlKAI8PSPBrls7OzuwYVj7Yr7tZRRMf3AHka7t5\n8+ZlY7wNLKiIXc8HmLAxbO3s13bsemx96/UQdr1IMAnTD1gWmM+YY3sTsuO6uroq7QsvvDAb49fA\nbL3L1v1+Pz223mWVmFigj4dVRvLz6UuxAzzIJqJlMfw9z5gxIxvDnjt7X+qhL74QBSLHF6JA5PhC\nFIgcX4gCaYq45wNfvIDChC1WItqPY5lpXvgB8n3imPjlA3FYRh3L5vIBNExUuuKKK7K+p59+utJm\nZadY4Ia3gQUsMRHLC4wbNmzIxsyfPz/r88FHTMhj+/d50ZM9Yx/0wuxmwUFeiGUluFmft5OJriwb\n0GcW+mAvgAuMXqSL7tXnMz5Z+Xn2vkTEy370xReiQBo6vpl1mNnDZva8mW0xs1tr/S1m9qCZbTOz\ndWbWuJqjEGJEEPnivwfgr1NKiwD8MYC/MrM/AnA7gIdSShcAeBjAHcNnphDiVNLQ8VNKPSmljbV/\nvwngRQAdAK4FcF9t2H0ArhsuI4UQp5YTEvfMbA6AiwE8CaA9pdQL9P1wMLO2esf5iDsvoLCIo0hk\nGRNnohleHi/mRcW9j3zkI5U2y15j4t6mTZsqbWY3K3Pla8Mz0cxHzQFcKPQwYdJnlLEsNCZQ+brv\nLNrNn5sJs+zZeeGXiby+zBbAsys9TCDzpdqYsBbJMI2UfAPyqDz2nkdr+9cjLO6Z2QQADwD4eu3L\n7/NBhze/Vwhxygh98c3sDPQ5/f0ppTW17l4za08p9ZrZNAD5J7LGwJ/+0d1ShBAnxrvvvkv/rMiI\nfvHvBfBCSum7A/rWAril9u+bAazxB/UzduzYY//J8YUYHs4880yMGzfu2H+D0bACj5mtAPAogC3o\n+3U+AbgTwNMAfgpgJoBuADemlLIFoJmllStXVvr8moWt0VjQgl8PsTU3+4nn15u+wgmzgQUQsR9a\nn/vc5yrtH/zgBw3PDeQZgqyaEAsm8WtQpg2wdaPXBpiGwfbXu+66qma7Zk3+851dz9vF7PRBNmx+\n2bPymgJbO7Py2j77j80vwx8XLU3O1uYeptH495plLb788stZ38KFCyvtTZs21a3A0/Dzm1L6DYBc\naevj6kbHCyFGHorcE6JA5PhCFIgcX4gCaYrE7kUOn+3ERJ1IHwtiYKKgF/eYiOXFGSYqsWCSBx54\noNJmJZFYGWcvHnZ0dGRjIgFKrOTT9u3bsz4fTMLKOfX29mZ9X/3qVyvte++9NxvDss58QAsTsby4\nFg1U8edix7E+L4wyYZu9dz6YzJdGB7hY6vc+ZGI0C1TzYjCzidkQLe0F6IsvRJHI8YUoEDm+EAUi\nxxeiQJoi7nmRw9dYZ0LMrl27sj4vjrAIKhaq6IUQJup4cYZlszGhadmyZZU2i/g7//zzsz4fbcbK\nV7FoNy9QMZsuv/zyrM/PHRMFlyxZkvV5YfI73/lONubOO+/M+vw9M4HKi3RMGH3qqaeyPp/Fx8qP\nRfYwZHvusfcuIiqzrEX/3rEIQ3YuH3XIhF/2TnkRezD0xReiQOT4QhSIHF+IAmmYnXfSFzBLF110\nUaXPB9mwABdW1cXbyjKwWECEr2Tz4Q9/OBvj1+YsI+riiy/O+jzMJra+9QFDzG62TvXnYppGJCuM\nVWu56667sr5bbrml0n700UezMTfddFPD6zH8HLNnzvC2RwNxvCbEnjGbzx07djQ8jgXneL2ABd1E\naG9vz/rY8/M61e7du+tm5+mLL0SByPGFKBA5vhAFIscXokCaEsDjhYi2tmolblZGmmV8+YAPJoix\nDDofHMOCc/wYJp6wAJPI3nIsWMbbyY5jc+ADPpiIxYSmCHPnzs36fHBMT09PNiZS4JGVufLPjz1P\nJqT5uWOZfz4DFMgDdlhJNHbcggULKm0WiMNEQS/usdLdkbljWXesL1poE9AXX4gikeMLUSByfCEK\npCkBPJdddlmlz29vxNa3bN3m12Q+MAjga0IPW0t6okEhft3PglDYWtKfnyVYsICPSKnnyPZjbM6v\nv/76rM9v9cXwAS5ArjOwOfD3zOyOBHKxuWMJOH7umBbCjvOwOWfz6e2MbOXGxrEt0dh2Zz7QZ/Pm\nzQrgEUIcR44vRIHI8YUoEDm+EAXSFHHvyiuvrPT5AB4mmjGRzme0sf3KIkE9TIjxNrAMt0iwDLMp\nIuowgYqJT17wY3YyGzxsDpiQ5s+/evXqbMwNN9yQ9XkBjNnk+6Jz7t+NiJAH5O8Gey5MhPTPIeoz\n/lzMJiYUMhs8bF78/fzkJz+RuCeEOI4cX4gCkeMLUSByfCEKpCnZedOnT6+0vajDRA8mcPgouWg2\nl8+cYsKIh4ltTNTxIlk0Q8pHJrL9/Ni5vF1MEItE8zHhsLOzM+u77bbbKu01a9aEruefAxP3/Jho\naSqf7ciyJiPzwkRBVu7MP6uIAAjkmZRMUGUCY6QUelScrYe++EIUiBxfiAKR4wtRIE1Z4/u1lW9H\n10x+3cbWOWyd6M/F1n9+DczWVcxOvyZklVgi98K2UmJrUG8Du1+2bvQVW5imwDLxvv3tb1faCxcu\nzMawNb5fbzJdxd9LpGoOkOsF0ezOSFnuyLvI5jcSSMV0Dva+eLuilabY/NVDX3whCkSOL0SBNHR8\nMzvLzJ4ys+fM7Hkzu7vW32JmD5rZNjNbZ2b5745CiBFJQ8dPKb0N4MqU0jIASwBcZWYrANwO4KGU\n0gUAHgZwx7BaKoQ4ZYTEvZRSf4TEWej7YXEAwLUArqj13wfgEfT9MMjwoooXbJg4xASxSCAF27uO\nCXWeSKYYCxTx98KEpmgWoSciQkYDhrzYduDAgWxMS0tLwz5WXjuSTRbJzmNlzyNlriLlsoBYliR7\nLpF3g72vfl6imZSR8ujMTla+ux6hNb6ZjTGz5wD0AHgkpfQCgPaUUi8ApJR6ALQNdg4hxMgh+sV/\nH8AyM5sEYJ2ZfQyA/1tI3STlLVu2HPt3W1tbFsIrhDh5enp60NvbGxp7Qn/HTykdNrNfArgUQK+Z\ntaeUes1sGoA99Y5j1XCFEKeWadOmYdq0acfamzdvrjs2ouq39iv2ZjYOwDUAngOwFsAttWE3A8iz\nN4QQI5LIF/9cAPdZn6IyBsD9KaVf1db8PzWzvwTQDeDGeifwQoTPMGPiEItI81Fy7DgWIeZFFSaM\neEGFiXRMRIrcC7PJH8ciuBiRUl9MRPLiXrTs1F133VVpX3fdddkYJp56UY5dr9F7Uc+mSAktRuR6\nkfcn+m74ZzPUCFV2f+y5M7vq0dDxU0pbACwn/fsBXB2+khBixKDIPSEKRI4vRIE0JTvPr1H8Woet\nYdi60a9T2fooUjo7EojD1lDsOG8nuxfWFwliYtljkdLZ7Di/p/vEiROzMWw/tlWrVlXa0VLWkRLU\n/vlFMw39M2aaDVu/e6IBYP6emYYSCephz47Z6cexyjpszk9kja8vvhAFIscXokDk+EIUiBxfiAJp\nirjniQg/kX3UWKkhJnD4czFhywsxTDCKlH9mxzHByIttrBQWw4tBTPxiZaf8+Y8cOZKNYc/FC1sT\nJkzIxkREq0gGHSs/xmzyz4rdbzRjzxMRT5mwxp7xOeec0/DckeAuNobdHxOf66EvvhAFIscXokDk\n+EIUiBxfiAJpirjnBbdIfXMm3HlhKSLEALngFj3Ow4TDSLQUy7zzUWOR/eeAXOiJ1vF/9NFHK+1P\nfepT2ZjPfvazWd+3vvWtSttn6wHA448/nvV52P1FyoYxIdaLWOx+2bm9IMaOY32ROY9kV0bLpPlo\nUGaT3ycBiO0J2Y+++EIUiBxfiAKR4wtRIE1Z4/u1h19jR0oaA3mwCstailQ5iaztovuqNbIR4Guv\nRnNS7zgPu5dIyeZ9+/ZlY77xjW9kfatXr660mTZwzz33ZH3f//73K+3W1tZsjJ9PNr/sOfhAquic\ne5g+w95FHwAWfTf8+SNBaQw2JqoX1ENffCEKRI4vRIHI8YUoEDm+EAXSFHGPiRoDYeWHmMjixTwm\n7rHyUacKJuB4YYkFnLDMLU+kdHf0uM7OzqzPB3ywTK5bb7016/vEJz5RaS9fnhVcpve8f//+Sptl\nH3rbmU1MgIuUO2P4d4qJZt7uUwl7f9gz9tmGLGuRES3RDuiLL0SRyPGFKBA5vhAFIscXokCaIu4N\np2DiiUSyDdxRtB9fimrSpEmh6/kIKibWMAHOC36vv/56NoaJQb6PiZlsT4KpU6dW2kwAnDlzZtZ3\n443VLRHnz5+fjXnhhReyvu7u7kqb7ZjsRatouSw/d1Hxi5Ubi+Aj9aL16/2cMztbWlqyvsh+jFFB\nsx764gtRIHJ8IQpEji9EgTRlje/LDPs1C8smG2rFFrb+iuzV54M5InuoAbnt0XWqt2n69OnZmEg2\nl59bAFi7dm3W53UNv3YHgK1bt2Z9l112WaXNnsErr7yS9fkKSqxiTGSu2Bz4QBUWyBWBBfCw98fr\nRtHMOB+QxAKd2LwwncoTKfU+GPriC1EgcnwhCkSOL0SByPGFKJCmiHs+K8oHRDABh4ksXgyKiixe\nLGFlqxtdi52HEQ3u8OIey0ZkfZESYaw81gMPPFBp//rXv87G+IATIA8smjdvXjZm06ZNWV9kj79I\n2Sk2B36O2XnYcR723rH5jFwv8r4yIS9yf+w4lsmo7DwhxKCEHd/MxpjZs2a2ttZuMbMHzWybma0z\ns9h2r0KI086JfPG/DmBgUPbtAB5KKV0A4GEAd5xKw4QQw0fI8c2sA8CfA/jXAd3XAriv9u/7AFx3\nak0TQgwXUXHvnwH8HYCBv863p5R6ASCl1GNmbdGLeqEnss8ZkIscTGRh4kykhJWHiTWRczO72f15\n21nmVkSsYTb9+Mc/bnjcY489lvXddtttWd/cuXMr7TVr1mRj1q9fn/VdcsklDW3wsHsZ6nGRjL0T\nEcMawcRLH/3J3g0m0kWiQSPXG4yGX3wz+ySA3pTSRgCDSdZDe2pCiKYT+eKvAPBpM/tzAOMATDSz\n+wH0mFl7SqnXzKYB2FPvBJs3bz727/b2dkyZMuUkzRZCePbu3Yu9e/eGxjZ0/JTSnQDuBAAzuwLA\n36SU/sLM/gnALQD+EcDNAPLfAWssWbKk0j7Z7X+EEDlTp06txGK8+OKLdcfaiayrBjj+p83sHAA/\nBTATQDeAG1NKB8kx6Zprrqn0bd++veG1WHCFD3aIrqcnT55caUdKcEfLXfu1evSHmr+XFStWZGM6\nOjoa2sWqszDbfQYdW6v7qjlAnv3HssIOHsweOyZMmFBp+2dQz04Pm3Pf568FcP3HP/eo9jNnzpxK\nm9n96quvZn1+3LnnnpuNiVTXYWOYNuB1jY0bNyKlRJfnJxS5l1L6PwD/V/v3fgBXn8jxQoiRgSL3\nhCgQOb4QBSLHF6JAmpKd58s+7dlT/ctfNICnt7e30mZ/FmTneu211yptVn7aw84dyc5j+DJUQC6I\n7d69OxvDSm77El1+LgFgxowZWV9PT0+lzYJXWNDNhg0bKm1WKn3RokVZnxeN2fP0WZJMxGL4Z8NE\nOvaM/Z50bW15zBl7Vl5sY3PX3t6e9XlRkJUm/8xnPpP1feUrXxn0+gDwox/9KOv70pe+lPXVQ198\nIQpEji9EgcjxhSgQOb4QBdIUce/888+vtJ955plKmwkxEdGKlSRikYg+24lFeh04cKDhuSP78rGI\nQyaIeRtYOTB2rm3btlXaLIuQRdL5eWEiKKv7vm7dukr77rvvzsZ40RXIIxPZ/fkxbH7Zu7Fz585K\n24t29fr8/TFhjYmsPtKUCZWsb/bs2ZX2L37xi2zM9ddfn/X5Z8XmgD33E6m1ry++EAUixxeiQOT4\nQhRIU9b4PlDCr1nYWpatN332GAtsYOuhyN5qfs3E9oNj+OsxbYDti+eDQNgeeCyLceHChZV2tJy3\nX2Pv27cvG/PGG29kff78bD93tsb32XGR0tKRcuIAMGvWrEqbVZ6JVOX52c9+lo05fPhw1ucDcVgA\nD9MwfDYeew+/+MUvZn1Lly6ttCPZrADP2KuHvvhCFIgcX4gCkeMLUSByfCEKpCninheEvGDERB0m\nzpx9duPNepjw4sUZJtz5gJrW1tZsDCvZ7EWsyH5wQC4iRTPTvFD6yCOPZGOuuuqqrM9n+jE7v/e9\n72V9nZ2dlfZFF12Ujdm4cWPWFwkm8e8BEyojmXfsXiL7IzIxjJ3Li3SsoCUrV7548eJKO1oK3WfZ\nsWCkk0VffCEKRI4vRIHI8YUokBMqrz2kC5ilSy+9tNLn1/zRtZZfA7IAHra2fOKJJyptbw87F1tz\nsz4fYBIt2ezPFS2hHNmrnSXg+OAcFjTFKun44BxWaeb555/P+iZNmlRps2pCXnsZ6j730f3qPT7Z\nB+Bz55+pD7AB8ipPALBy5cpK+/HHH8/GsEo6X/7ylytt9qwic7Vhw4a65bX1xReiQOT4QhSIHF+I\nApHjC1EgTRH3fHCM3xOOBYUcOXIk6/NZWWwvMpZxdfnll1faTz/9dDbGlwBne75feeWVWd+WLVuy\nPg8L/PHBSCzD7Wtf+1rW57MWWTDSz3/+84bXY+KQr+4DAJ///Ocr7U2bNmVjGL5a0qFDh7IxH//4\nxyttlpHJ7s8/d5b59+STT2Z9/jmwd4zhS25H91X0IjLLsmPCnd/jz7+bAHDDDTdkfatXr660t27d\nevrFvdF8lPgQAAADmklEQVS8Q24kCmwkMlrtBoCurq7TbcKQiP5V53TTNMdnP9lGC+zPhqOB0Wo3\nMHodn/32MRLRGl+IAmlKks7FF1+M7u7uY1VHfaLJeeedlx3Dglf8Wocl0lx44YVZn9cG2NrOb8s0\n8Nfkrq4uzJ07l9oZ+U2GVYjxugcLjGGVe3yAErv+kiVLABy3m12PBcawZBB/z9HfIvwzZjqHv7+B\n9zZ+/Hi0t7fT+/PPnS1p2HZV/jmw7bIY/td3Vkmn34bt27cfu3b/3PfDgrTY/fkqyWw7N6Zv+Xd/\n69at2Zh+miLuDesFhBB1qSfuDbvjCyFGHlrjC1EgcnwhCqQpjm9mq8zsJTN72cy+2YxrDhUzu8fM\nes1s84C+FjN70My2mdk6M2tcCqjJmFmHmT1sZs+b2RYzu7XWP6JtN7OzzOwpM3uuZvvdtf4RbXc/\nZjbGzJ41s7W19qiwe9gd38zGAPgXAH8GYBGAm8zsj4b7uifBD9Fn60BuB/BQSukCAA8DuKPpVjXm\nPQB/nVJaBOCPAfxVbZ5HtO0ppbcBXJlSWgZgCYCrzGwFRrjdA/g6gBcGtEeH3SmlYf0PwEcA/PeA\n9u0Avjnc1z1Jm2cD2Dyg/RKA9tq/pwF46XTbGLiH/wRw9WiyHcCHADwNYOFosBtAB4D/BfAxAGtH\n07vSjF/1ZwAYuAXpq7W+0URbSqkXAFJKPQDaGow/rZjZHAAXA3gSfS/hiLa99uvycwB6ADySUnoB\no8BuAP8M4O8ADPzT2GiwW+LeEBmxfwM1swkAHgDw9ZTSm8htHXG2p5TeT32/6ncA+BMz+xhGuN1m\n9kkAvSmljQAGK/czouzupxmO/xqAgaFzHbW+0USvmbUDgJlNA7DnNNtDMbMz0Of096eU1tS6R4Xt\nAJBSOgzglwAuxci3ewWAT5tZF4B/R582cT+AnhFuN4DmOP4zAM43s9lm9kEAXwCwtgnXPRkM1Z/i\nawHcUvv3zQDW+ANGCPcCeCGl9N0BfSPadjNr7Ve+zWwcgGsAPIcRbndK6c6U0qyU0lz0vdMPp5T+\nAsB/YQTbfYwmiSCrAGwDsB3A7adb2Ghg678BeB3A2wB2AfgygBYAD9Xu4UEAk0+3ncTuFQD+AGAj\n+hzn2dq8nzOSbQdwUc3W5wBsAvC3tf4Rbbe7hytwXNwbFXYrZFeIApG4J0SByPGFKBA5vhAFIscX\nokDk+EIUiBxfiAKR4wtRIHJ8IQrk/wHoEmTDvpe1LgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2f8bbc54e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "obs,r,done,_=env.step(1)\n",
    "print(r, done)\n",
    "plt.imshow(obs[0], cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using simple convolutional neural network.\n",
    "\n",
    "![scheme](https://s18.postimg.org/gbmsq6gmx/dqn_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=gpu0,floatX=float32\n"
     ]
    }
   ],
   "source": [
    "#setup and import theano/lasagne. Prefer GPU\n",
    "%env THEANO_FLAGS=device=gpu0,floatX=float32\n",
    "\n",
    "import theano, lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "from agentnet.memory import WindowAugmentation, LSTMCell\n",
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "from agentnet.target_network import TargetNetwork\n",
    "from agentnet.experiments.openai_gym.pool import EnvPool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define your NN which probably solve the environment. \n",
    "\n",
    "#### Tips:\n",
    "1. Main component are likely to be ```Conv2D``` and ```Pool2DLayer```\n",
    "2. Batch normalization here might speeds up training but may get unstable if you use small experience replay buffer\n",
    "3. Last layers should be Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.nonlinearities import rectify, tanh, softmax\n",
    "\n",
    "#observation\n",
    "observation_layer = InputLayer((None,)+observation_shape,)\n",
    "\n",
    "#4-tick window over images\n",
    "\n",
    "prev_wnd = InputLayer((None,FRAME_NUMBER)+observation_shape) \n",
    "new_wnd = WindowAugmentation(observation_layer,prev_wnd)\n",
    "        \n",
    "#reshape to (frame, h,w). If you don't use grayscale, 4 should become 12.\n",
    "wnd_reshape = reshape(new_wnd, (-1,FRAME_NUMBER*observation_shape[0])+observation_shape[1:])\n",
    "\n",
    "\n",
    "layer = Conv2DLayer(wnd_reshape, num_filters=20, filter_size=(3, 3), \n",
    "                    nonlinearity=rectify, pad='same')\n",
    "\n",
    "layer = Conv2DLayer(layer, num_filters=40, filter_size=(3, 3), \n",
    "                    nonlinearity=rectify, pad='same')\n",
    "\n",
    "\n",
    "layer = FlattenLayer(layer)\n",
    "\n",
    "layer = DenseLayer(layer, num_units=256, nonlinearity=tanh)  \n",
    "\n",
    "dense = DenseLayer(layer, num_units=128, nonlinearity=tanh)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#baseline for all qvalues\n",
    "qvalues_layer = DenseLayer(dense, num_units=n_actions, \n",
    "                           nonlinearity=None, name='qval')\n",
    "        \n",
    "#sample actions proportionally to policy_layer\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targetnet = TargetNetwork(qvalues_layer)\n",
    "qvalues_old = targetnet.output_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              policy_estimators=(qvalues_layer,qvalues_old),\n",
    "              agent_states={new_wnd:prev_wnd},\n",
    "              action_layers=action_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, W, b, W, b, qval.W, qval.b]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:22:52,036] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:22:52,052] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:22:52,070] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:22:52,095] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:22:52,115] Making new env: ppaquette/DoomBasic-v0\n"
     ]
    }
   ],
   "source": [
    "pool = EnvPool(agent,make_env, \n",
    "               n_games=5, #parallel games (only 1 so far)\n",
    "               max_size=int(1e4)) #experience replay pool holding last 1k sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning\n",
    "* An agent has a method that produces symbolic environment interaction sessions\n",
    "* Such sessions are in sequences of observations, agent memory, actions, q-values,etc\n",
    "  * one has to pre-define maximum session length.\n",
    "\n",
    "* SessionPool also stores rewards (Q-learning objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(128)\n",
    "\n",
    "_,_,_,_,(qvalues_seq,old_qvalues_seq) = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get reference Qvalues according to Qlearning algorithm\n",
    "from agentnet.learning import qlearning\n",
    "\n",
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      qvalues_target=old_qvalues_seq,\n",
    "                                                      gamma_or_gammas=0.99)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "updates = lasagne.updates.adam(loss, weights)\n",
    "\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have ```tqdm```, remove the first line and ```tqdm_notebook``` from second line\n",
    "\n",
    "Loop may take years to finish.\n",
    "\n",
    "You may consider interrupting early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n",
      "/usr/local/lib/python3.4/dist-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=1] Warning! Appending sessions to empty or broken pool. Old pool sessions, if any, are disposed.\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=10\tepsilon=0.967\treward/step=-0.89333\n",
      "iter=20\tepsilon=0.936\treward/step=-2.07667\n",
      "iter=30\tepsilon=0.905\treward/step=-2.45556\n",
      "iter=40\tepsilon=0.875\treward/step=-2.64000\n",
      "iter=50\tepsilon=0.846\treward/step=-2.46400\n",
      "iter=60\tepsilon=0.819\treward/step=-2.47889\n",
      "iter=70\tepsilon=0.792\treward/step=-2.57619\n",
      "iter=80\tepsilon=0.766\treward/step=-2.75000\n",
      "iter=90\tepsilon=0.741\treward/step=-2.90741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:25:53,097] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:25:53,107] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=100\tepsilon=0.717\treward/step=-2.85867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:25:54,031] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 26 timesteps with reward=-49.0\n",
      "iter=110\tepsilon=0.693\treward/step=-2.89758\n",
      "iter=120\tepsilon=0.670\treward/step=-2.91056\n",
      "iter=130\tepsilon=0.648\treward/step=-2.93128\n",
      "iter=140\tepsilon=0.627\treward/step=-2.99810\n",
      "iter=150\tepsilon=0.607\treward/step=-2.91244\n",
      "iter=160\tepsilon=0.587\treward/step=-2.97833\n",
      "iter=170\tepsilon=0.567\treward/step=-2.90353\n",
      "iter=180\tepsilon=0.549\treward/step=-2.96259\n",
      "iter=190\tepsilon=0.531\treward/step=-3.03825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:28:53,936] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:28:53,947] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=200\tepsilon=0.513\treward/step=-3.01833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:28:55,857] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 70 timesteps with reward=-435.0\n",
      "iter=210\tepsilon=0.497\treward/step=-3.03302\n",
      "iter=220\tepsilon=0.480\treward/step=-3.09364\n",
      "iter=230\tepsilon=0.465\treward/step=-3.10957\n",
      "iter=240\tepsilon=0.449\treward/step=-3.12389\n",
      "iter=250\tepsilon=0.435\treward/step=-3.12480\n",
      "iter=260\tepsilon=0.420\treward/step=-3.10769\n",
      "iter=270\tepsilon=0.407\treward/step=-3.04617\n",
      "iter=280\tepsilon=0.393\treward/step=-3.01786\n",
      "iter=290\tepsilon=0.380\treward/step=-3.01103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:31:59,533] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:31:59,543] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=300\tepsilon=0.368\treward/step=-3.03400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:32:01,488] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 70 timesteps with reward=-390.0\n",
      "iter=310\tepsilon=0.356\treward/step=-2.91505\n",
      "iter=320\tepsilon=0.344\treward/step=-2.94792\n",
      "iter=330\tepsilon=0.333\treward/step=-2.96768\n",
      "iter=340\tepsilon=0.322\treward/step=-2.94353\n",
      "iter=350\tepsilon=0.311\treward/step=-2.92076\n",
      "iter=360\tepsilon=0.301\treward/step=-2.90222\n",
      "iter=370\tepsilon=0.291\treward/step=-2.92018\n",
      "iter=380\tepsilon=0.282\treward/step=-2.93632\n",
      "iter=390\tepsilon=0.273\treward/step=-2.91709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:35:09,505] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:35:09,516] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=400\tepsilon=0.264\treward/step=-2.91650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:35:11,476] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 70 timesteps with reward=-370.0\n",
      "iter=410\tepsilon=0.255\treward/step=-2.82943\n",
      "iter=420\tepsilon=0.247\treward/step=-2.83095\n",
      "iter=430\tepsilon=0.239\treward/step=-2.83085\n",
      "iter=440\tepsilon=0.231\treward/step=-2.84379\n",
      "iter=450\tepsilon=0.223\treward/step=-2.84400\n",
      "iter=460\tepsilon=0.216\treward/step=-2.76942\n",
      "iter=470\tepsilon=0.209\treward/step=-2.76709\n",
      "iter=480\tepsilon=0.202\treward/step=-2.71625\n",
      "iter=490\tepsilon=0.195\treward/step=-2.65279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:38:24,024] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:38:24,035] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=500\tepsilon=0.189\treward/step=-2.65653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:38:26,006] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 70 timesteps with reward=-370.0\n",
      "iter=510\tepsilon=0.183\treward/step=-2.67634\n",
      "iter=520\tepsilon=0.177\treward/step=-2.69474\n",
      "iter=530\tepsilon=0.171\treward/step=-2.65925\n",
      "iter=540\tepsilon=0.165\treward/step=-2.64284\n",
      "iter=550\tepsilon=0.160\treward/step=-2.67661\n",
      "iter=560\tepsilon=0.155\treward/step=-2.70619\n",
      "iter=570\tepsilon=0.150\treward/step=-2.63509\n",
      "iter=580\tepsilon=0.145\treward/step=-2.60012\n",
      "iter=590\tepsilon=0.140\treward/step=-2.57887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:41:42,777] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:41:42,788] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=600\tepsilon=0.135\treward/step=-2.46478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:41:43,332] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 10 timesteps with reward=47.0\n",
      "iter=610\tepsilon=0.131\treward/step=-2.44546\n",
      "iter=620\tepsilon=0.127\treward/step=-2.36054\n",
      "iter=630\tepsilon=0.122\treward/step=-2.33270\n",
      "iter=640\tepsilon=0.118\treward/step=-2.26344\n",
      "iter=650\tepsilon=0.115\treward/step=-2.17210\n",
      "iter=660\tepsilon=0.111\treward/step=-2.15909\n",
      "iter=670\tepsilon=0.107\treward/step=-2.11483\n",
      "iter=680\tepsilon=0.104\treward/step=-2.01971\n",
      "iter=690\tepsilon=0.100\treward/step=-2.00995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:45:04,479] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:45:04,490] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=700\tepsilon=0.097\treward/step=-1.95962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:45:04,928] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 5 timesteps with reward=76.0\n",
      "iter=710\tepsilon=0.094\treward/step=-1.94958\n",
      "iter=720\tepsilon=0.091\treward/step=-1.91083\n",
      "iter=730\tepsilon=0.088\treward/step=-1.86521\n",
      "iter=740\tepsilon=0.085\treward/step=-1.82910\n",
      "iter=750\tepsilon=0.082\treward/step=-1.79298\n",
      "iter=760\tepsilon=0.079\treward/step=-1.80526\n",
      "iter=770\tepsilon=0.077\treward/step=-1.79931\n",
      "iter=780\tepsilon=0.074\treward/step=-1.78402\n",
      "iter=790\tepsilon=0.072\treward/step=-1.75975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:48:31,147] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:48:31,157] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=800\tepsilon=0.069\treward/step=-1.71883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:48:31,701] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 11 timesteps with reward=46.0\n",
      "iter=810\tepsilon=0.067\treward/step=-1.67021\n",
      "iter=820\tepsilon=0.065\treward/step=-1.62268\n",
      "iter=830\tepsilon=0.063\treward/step=-1.57679\n",
      "iter=840\tepsilon=0.061\treward/step=-1.51516\n",
      "iter=850\tepsilon=0.059\treward/step=-1.46212\n",
      "iter=860\tepsilon=0.057\treward/step=-1.39574\n",
      "iter=870\tepsilon=0.055\treward/step=-1.30429\n",
      "iter=880\tepsilon=0.053\treward/step=-1.24886\n",
      "iter=890\tepsilon=0.051\treward/step=-1.12285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:52:04,102] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:52:04,113] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=900\tepsilon=0.050\treward/step=-1.03896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:52:04,420] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1 timesteps with reward=96.0\n",
      "iter=910\tepsilon=0.048\treward/step=-0.94901\n",
      "iter=920\tepsilon=0.047\treward/step=-0.89283\n",
      "iter=930\tepsilon=0.045\treward/step=-0.79090\n",
      "iter=940\tepsilon=0.044\treward/step=-0.71369\n",
      "iter=950\tepsilon=0.042\treward/step=-0.62393\n",
      "iter=960\tepsilon=0.041\treward/step=-0.54208\n",
      "iter=970\tepsilon=0.039\treward/step=-0.44825\n",
      "iter=980\tepsilon=0.038\treward/step=-0.34857\n",
      "iter=990\tepsilon=0.037\treward/step=-0.28108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:55:42,851] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:55:42,862] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1000\tepsilon=0.036\treward/step=-0.19300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:55:43,362] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 9 timesteps with reward=52.0\n",
      "iter=1010\tepsilon=0.035\treward/step=-0.10528\n",
      "iter=1020\tepsilon=0.033\treward/step=-0.00627\n",
      "iter=1030\tepsilon=0.032\treward/step=0.08343\n",
      "iter=1040\tepsilon=0.031\treward/step=0.16481\n",
      "iter=1050\tepsilon=0.030\treward/step=0.22425\n",
      "iter=1060\tepsilon=0.029\treward/step=0.30208\n",
      "iter=1070\tepsilon=0.028\treward/step=0.37159\n",
      "iter=1080\tepsilon=0.027\treward/step=0.44673\n",
      "iter=1090\tepsilon=0.026\treward/step=0.50795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:59:30,017] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 22:59:30,028] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1100\tepsilon=0.026\treward/step=0.55430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 22:59:30,498] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 8 timesteps with reward=57.0\n",
      "iter=1110\tepsilon=0.025\treward/step=0.61165\n",
      "iter=1120\tepsilon=0.024\treward/step=0.68137\n",
      "iter=1130\tepsilon=0.023\treward/step=0.72631\n",
      "iter=1140\tepsilon=0.022\treward/step=0.78135\n",
      "iter=1150\tepsilon=0.022\treward/step=0.84887\n",
      "iter=1160\tepsilon=0.021\treward/step=0.90793\n",
      "iter=1170\tepsilon=0.020\treward/step=0.96678\n",
      "iter=1180\tepsilon=0.020\treward/step=1.03068\n",
      "iter=1190\tepsilon=0.019\treward/step=1.08667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:03:26,067] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 23:03:26,077] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1200\tepsilon=0.018\treward/step=1.13611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:03:26,382] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1 timesteps with reward=96.0\n",
      "iter=1210\tepsilon=0.018\treward/step=1.19107\n",
      "iter=1220\tepsilon=0.017\treward/step=1.23913\n",
      "iter=1230\tepsilon=0.017\treward/step=1.27491\n",
      "iter=1240\tepsilon=0.016\treward/step=1.33339\n",
      "iter=1250\tepsilon=0.016\treward/step=1.40709\n",
      "iter=1260\tepsilon=0.015\treward/step=1.46878\n",
      "iter=1270\tepsilon=0.015\treward/step=1.51958\n",
      "iter=1280\tepsilon=0.014\treward/step=1.56203\n",
      "iter=1290\tepsilon=0.014\treward/step=1.61581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:07:39,361] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 23:07:39,372] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1300\tepsilon=0.013\treward/step=1.67944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:07:39,678] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1 timesteps with reward=96.0\n",
      "iter=1310\tepsilon=0.013\treward/step=1.73684\n",
      "iter=1320\tepsilon=0.012\treward/step=1.78737\n",
      "iter=1330\tepsilon=0.012\treward/step=1.84301\n",
      "iter=1340\tepsilon=0.011\treward/step=1.91517\n",
      "iter=1350\tepsilon=0.011\treward/step=1.97427\n",
      "iter=1360\tepsilon=0.011\treward/step=2.02784\n",
      "iter=1370\tepsilon=0.010\treward/step=2.11182\n",
      "iter=1380\tepsilon=0.010\treward/step=2.15338\n",
      "iter=1390\tepsilon=0.010\treward/step=2.20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:12:08,373] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 23:12:08,392] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1400\tepsilon=0.009\treward/step=2.25529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:12:09,004] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 4 timesteps with reward=81.0\n",
      "iter=1410\tepsilon=0.009\treward/step=2.31551\n",
      "iter=1420\tepsilon=0.009\treward/step=2.37986\n",
      "iter=1430\tepsilon=0.009\treward/step=2.42317\n",
      "iter=1440\tepsilon=0.008\treward/step=2.47120\n",
      "iter=1450\tepsilon=0.008\treward/step=2.52280\n",
      "iter=1460\tepsilon=0.008\treward/step=2.55954\n",
      "iter=1470\tepsilon=0.007\treward/step=2.60027\n",
      "iter=1480\tepsilon=0.007\treward/step=2.66036\n",
      "iter=1490\tepsilon=0.007\treward/step=2.71937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:17:50,987] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 23:17:51,007] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1500\tepsilon=0.007\treward/step=2.75338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:17:51,596] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 4 timesteps with reward=81.0\n",
      "iter=1510\tepsilon=0.007\treward/step=2.81139\n",
      "iter=1520\tepsilon=0.006\treward/step=2.86311\n",
      "iter=1530\tepsilon=0.006\treward/step=2.89181\n",
      "iter=1540\tepsilon=0.006\treward/step=2.93303\n",
      "iter=1550\tepsilon=0.006\treward/step=2.97944\n",
      "iter=1560\tepsilon=0.006\treward/step=3.03829\n",
      "iter=1570\tepsilon=0.005\treward/step=3.07843\n",
      "iter=1580\tepsilon=0.005\treward/step=3.12232\n",
      "iter=1590\tepsilon=0.005\treward/step=3.17895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:23:16,404] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 23:23:16,415] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1600\tepsilon=0.005\treward/step=3.22196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:23:16,875] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 4 timesteps with reward=81.0\n",
      "iter=1610\tepsilon=0.005\treward/step=3.27342\n",
      "iter=1620\tepsilon=0.005\treward/step=3.32428\n",
      "iter=1630\tepsilon=0.004\treward/step=3.36973\n",
      "iter=1640\tepsilon=0.004\treward/step=3.41504\n",
      "iter=1650\tepsilon=0.004\treward/step=3.46000\n",
      "iter=1660\tepsilon=0.004\treward/step=3.50831\n",
      "iter=1670\tepsilon=0.004\treward/step=3.54743\n",
      "iter=1680\tepsilon=0.004\treward/step=3.57817\n",
      "iter=1690\tepsilon=0.004\treward/step=3.62020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:28:55,773] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 23:28:55,785] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1700\tepsilon=0.003\treward/step=3.65847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:28:56,249] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 4 timesteps with reward=81.0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dcc2d0a0e676>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/agentnet/experiments/openai_gym/pool.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, n_steps, append, max_size, add_last_observation, preprocess)\u001b[0m\n\u001b[1;32m    204\u001b[0m             self.experience_replay.append_sessions(observation_tensor, action_tensor, reward_tensor,\n\u001b[1;32m    205\u001b[0m                                                    \u001b[0mis_alive_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreceding_memory_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                                                    max_pool_size=max_size or self.max_size)\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     def evaluate(self, n_games=1, save_path=\"./records\", use_monitor=True, record_video=True, verbose=True,\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/agentnet/environment/session_pool.py\u001b[0m in \u001b[0;36mappend_sessions\u001b[0;34m(self, observation_sequences, action_sequences, reward_seq, is_alive, prev_memories, max_pool_size)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 prev_memory_tensors = [np.concatenate((prev_mem.get_value(), new_prev_mem), axis=0)\n\u001b[1;32m    246\u001b[0m                                            \u001b[0;32mfor\u001b[0m \u001b[0mprev_mem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_prev_mem\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                                            zip(self.preceding_agent_memories, prev_memories)]\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mprev_memory_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/agentnet/environment/session_pool.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprev_memories\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 prev_memory_tensors = [np.concatenate((prev_mem.get_value(), new_prev_mem), axis=0)\n\u001b[0;32m--> 246\u001b[0;31m                                            \u001b[0;32mfor\u001b[0m \u001b[0mprev_mem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_prev_mem\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m                                            zip(self.preceding_agent_memories, prev_memories)]\n\u001b[1;32m    248\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange, tqdm_notebook\n",
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "\n",
    "epoch_counter = 1\n",
    "rewards = {}\n",
    "action_layer.epsilon.set_value(1.0)\n",
    "\n",
    "for i in tqdm_notebook(range(10000)):  \n",
    "    \n",
    "    \n",
    "    #train\n",
    "    pool.update(SEQ_LENGTH,append=True)\n",
    "    \n",
    "    loss = train_step()\n",
    "    \n",
    "    targetnet.load_weights(0.05)\n",
    "    \n",
    "    ##update resolver's epsilon (chance of random action instead of optimal one)\n",
    "    current_epsilon = 1.0 * np.exp(-epoch_counter/300.)\n",
    "    action_layer.epsilon.set_value(np.float32(current_epsilon))\n",
    "    \n",
    "    if epoch_counter % 10 == 0:\n",
    "        #average reward per game tick in current experience replay pool\n",
    "        pool_mean_reward = pool.experience_replay.rewards.get_value().mean()\n",
    "        print(\"iter=%i\\tepsilon=%.3f\\treward/step=%.5f\"%(epoch_counter,\n",
    "                                                         current_epsilon,\n",
    "                                                         pool_mean_reward))\n",
    "        \n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%100 == 0:\n",
    "        rewards[epoch_counter] = pool.evaluate(record_video=False)\n",
    "    \n",
    "    epoch_counter  += 1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating results\n",
    " * Here we plot learning curves and sample testimonials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2f1d5dbcc0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEACAYAAABGYoqtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpKTQkJERHJSSIiISE7/Hxe/LCKqMLmYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2f1d6422b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time,rw = zip(*sorted(list(rewards.items()),key=lambda p:p[0]))\n",
    "plt.plot(time,list(map(np.mean,rw)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:29:27,435] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-03-18 23:29:27,453] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:29:27,811] Starting new video recorder writing to /home/golovanov/repo/git/Practical_RL/week4/records/openaigym.video.17.29863.video000000.mp4\n",
      "[2017-03-18 23:29:28,176] Starting new video recorder writing to /home/golovanov/repo/git/Practical_RL/week4/records/openaigym.video.17.29863.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 3 timesteps with reward=86.0\n",
      "Episode finished after 1 timesteps with reward=96.0\n",
      "Episode finished after 1 timesteps with reward=96.0\n",
      "Episode finished after 4 timesteps with reward=81.0\n",
      "Episode finished after 3 timesteps with reward=86.0\n",
      "Episode finished after 1 timesteps with reward=96.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:29:28,941] Starting new video recorder writing to /home/golovanov/repo/git/Practical_RL/week4/records/openaigym.video.17.29863.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 4 timesteps with reward=81.0\n",
      "Episode finished after 2 timesteps with reward=91.0\n",
      "Episode finished after 7 timesteps with reward=66.0\n",
      "Episode finished after 3 timesteps with reward=86.0\n",
      "Episode finished after 7 timesteps with reward=66.0\n",
      "Episode finished after 6 timesteps with reward=71.0\n",
      "Episode finished after 3 timesteps with reward=86.0\n",
      "Episode finished after 6 timesteps with reward=71.0\n",
      "Episode finished after 6 timesteps with reward=71.0\n",
      "Episode finished after 9 timesteps with reward=52.0\n",
      "Episode finished after 3 timesteps with reward=86.0\n",
      "Episode finished after 4 timesteps with reward=81.0\n",
      "Episode finished after 5 timesteps with reward=76.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:29:31,806] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1 timesteps with reward=96.0\n",
      "mean session score=81.050000.5\n"
     ]
    }
   ],
   "source": [
    "action_layer.epsilon.set_value(0.001)\n",
    "rw = pool.evaluate(n_games=20,save_path=\"./records\",record_video=True)\n",
    "print(\"mean session score=%f.5\"%np.mean(rw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.utils.persistence import save,load\n",
    "#save for display\n",
    "#save(action_layer,\"doombasic_dqn_2000.pcl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./records/openaigym.video.17.29863.video000008.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import os\n",
    "from random import choice\n",
    "#select the one you want\n",
    "videos = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "video_path=\"./records/\"+choice(videos)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework II\n",
    "Get it work. We want stable positive score :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus assignment II\n",
    "* Better env\n",
    "  * Switch to DoomDefendCenter, DoomHealthGathering, DoomDeathmatch __or__ any atari game you want.\n",
    "  * Try to get `better_than_random` score on any of those environments __(2+++ pts)__\n",
    "  * Deploy a better network. Doom will likely need some recurrent netsle\n",
    "     * Find an arcitecture which maxsimizes score __(bonus points depend on your ```mean_reward```)__  \n",
    "     * Bonus can get large as you approach state-of-the-art\n",
    "     \n",
    "* Deploy a different RL algorithm\n",
    "  * Try at least two RL algorithms which had been learned during the course and try to compare them on ```mean_reward``` with similar training time (**plot** or **table** would be good idea) __(3 pts)__\n",
    "  * See the note in assignment 4.1 on how to train on-policy\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
