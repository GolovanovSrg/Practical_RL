{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple q-learning agent with experience replay\n",
    "\n",
    "We re-write q-learning algorithm using _agentnet_ - a helper for lasagne that implements some RL techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS='floatX=float32'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "%env THEANO_FLAGS='floatX=float32'\n",
    "\n",
    "#XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment setup\n",
    "* Here we simply load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:35:16,471] Making new env: Acrobot-v1\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "make_env = lambda: gym.make(\"Acrobot-v1\")\n",
    "\n",
    "env=make_env()\n",
    "env.reset()\n",
    "\n",
    "state_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAAEACAYAAABCu5jVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9n/eJQDvY0KxCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd21ab7d3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "del env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "[2017-03-18 23:35:19,765] The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GT 730M (CNMeM is enabled with initial size: 70.0% of memory, cuDNN 5004)\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import elu\n",
    "\n",
    "\n",
    "#image observation at current tick goes here, shape = (sample_i,x,y,color)\n",
    "observation_layer = InputLayer((None,)+state_shape)\n",
    "layer = DenseLayer(observation_layer, num_units=256, nonlinearity=elu)\n",
    "layer = DenseLayer(layer, num_units=128, nonlinearity=elu)\n",
    "qvalues_layer = DenseLayer(layer, num_units=n_actions, nonlinearity=None, name=\"q-values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking actions is done by yet another layer, that implements $ \\epsilon$ -greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer)\n",
    "\n",
    "#set starting epsilon\n",
    "action_layer.epsilon.set_value(np.float32(0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent\n",
    "\n",
    "We define an agent entirely composed of a lasagne network:\n",
    "* Observations as InputLayer(s)\n",
    "* Actions as intermediate Layer(s)\n",
    "* `policy_estimators` is \"whatever else you want to keep track of\"\n",
    "\n",
    "Each parameter can be either one layer or a list of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              action_layers=action_layer,\n",
    "              policy_estimators=qvalues_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, q-values.W, q-values.b]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:35:34,123] Making new env: Acrobot-v1\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "pool = EnvPool(agent,make_env,n_games=1,max_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions: [[2 2 2 2 0]]\n",
      "rewards: [[-1. -1. -1. -1.  0.]]\n",
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 6.93 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "obs_log,action_log,reward_log,_,_,_  = pool.interact(5)\n",
    "\n",
    "\n",
    "print('actions:',action_log)\n",
    "print('rewards:',reward_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we'll train on rollouts of 10 steps (required by n-step algorithms and rnns later)\n",
    "SEQ_LENGTH=10\n",
    "\n",
    "#load first sessions (this function calls interact and stores sessions in the pool)\n",
    "\n",
    "for _ in range(100):\n",
    "    pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q-learning\n",
    "\n",
    "We shall now define a function that replays recent game sessions and updates network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100)\n",
    "qvalues_seq = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True,\n",
    ")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2, like you implemented before in lasagne.\n",
    "\n",
    "from agentnet.learning import qlearning\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      gamma_or_gammas=0.99,\n",
    "                                                      n_steps=1,)\n",
    "\n",
    "#compute mean loss over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get weight updates\n",
    "updates = lasagne.updates.adam(loss,weights,learning_rate=1e-4)\n",
    "\n",
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run\n",
    "\n",
    "Play full session with an untrained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:36:18,999] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:36:19,006] Clearing 8 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:36:19,008] Starting new video recorder writing to /home/golovanov/repo/git/Practical_RL/week4/records/openaigym.video.0.31928.video000000.mp4\n",
      "[2017-03-18 23:36:29,066] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 500 timesteps with reward=-500.0\n"
     ]
    }
   ],
   "source": [
    "#for MountainCar-v0 evaluation session is cropped to 200 ticks\n",
    "untrained_reward = pool.evaluate(save_path=\"./records\",record_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./records/openaigym.video.0.31928.video000000.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./records/\"+video_names[-1])) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch_counter = 1 #starting epoch\n",
    "rewards = {} #full game rewards\n",
    "target_score = -90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 99/10000 [00:06<10:37, 15.54it/s][2017-03-18 23:36:47,523] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:36:47,528] Clearing 4 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 498 timesteps with reward=-497.0\n",
      "Episode finished after 500 timesteps with reward=-500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:36:48,947] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  1%|          | 101/10000 [00:08<46:23,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 500 timesteps with reward=-500.0\n",
      "iter=100\tepsilon=0.910\n",
      "Current score(mean over 3) = -499.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 199/10000 [00:14<10:36, 15.41it/s][2017-03-18 23:36:55,521] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:36:55,524] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 500 timesteps with reward=-500.0\n",
      "Episode finished after 500 timesteps with reward=-500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:36:56,971] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  2%|▏         | 201/10000 [00:16<46:52,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 500 timesteps with reward=-500.0\n",
      "iter=200\tepsilon=0.828\n",
      "Current score(mean over 3) = -500.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 299/10000 [00:23<11:16, 14.33it/s][2017-03-18 23:37:04,713] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:37:04,716] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 482 timesteps with reward=-481.0\n",
      "Episode finished after 376 timesteps with reward=-375.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:37:05,882] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  3%|▎         | 301/10000 [00:25<40:21,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 361 timesteps with reward=-360.0\n",
      "iter=300\tepsilon=0.754\n",
      "Current score(mean over 3) = -405.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 399/10000 [00:32<11:41, 13.68it/s][2017-03-18 23:37:13,388] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:37:13,393] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 465 timesteps with reward=-464.0\n",
      "Episode finished after 418 timesteps with reward=-417.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:37:14,680] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  4%|▍         | 401/10000 [00:33<42:46,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 500 timesteps with reward=-500.0\n",
      "iter=400\tepsilon=0.687\n",
      "Current score(mean over 3) = -460.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 499/10000 [00:40<10:29, 15.10it/s][2017-03-18 23:37:21,294] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:37:21,297] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 288 timesteps with reward=-287.0\n",
      "Episode finished after 134 timesteps with reward=-133.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:37:22,212] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  5%|▌         | 501/10000 [00:41<34:33,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 359 timesteps with reward=-358.0\n",
      "iter=500\tepsilon=0.626\n",
      "Current score(mean over 3) = -259.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 598/10000 [00:49<14:00, 11.19it/s][2017-03-18 23:37:30,893] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:37:30,897] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 189 timesteps with reward=-188.0\n",
      "Episode finished after 163 timesteps with reward=-162.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:37:31,446] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  6%|▌         | 602/10000 [00:50<22:10,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 222 timesteps with reward=-221.0\n",
      "iter=600\tepsilon=0.571\n",
      "Current score(mean over 3) = -190.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 698/10000 [00:58<12:07, 12.79it/s][2017-03-18 23:37:40,010] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:37:40,016] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 208 timesteps with reward=-207.0\n",
      "Episode finished after 218 timesteps with reward=-217.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:37:40,662] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  7%|▋         | 702/10000 [00:59<23:00,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 246 timesteps with reward=-245.0\n",
      "iter=700\tepsilon=0.522\n",
      "Current score(mean over 3) = -223.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 799/10000 [01:07<15:20, 10.00it/s][2017-03-18 23:37:48,960] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:37:48,963] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 188 timesteps with reward=-187.0\n",
      "Episode finished after 178 timesteps with reward=-177.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:37:49,526] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  8%|▊         | 801/10000 [01:08<28:03,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 155 timesteps with reward=-154.0\n",
      "iter=800\tepsilon=0.477\n",
      "Current score(mean over 3) = -172.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 898/10000 [01:17<12:34, 12.06it/s][2017-03-18 23:37:58,546] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:37:58,549] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 240 timesteps with reward=-239.0\n",
      "Episode finished after 171 timesteps with reward=-170.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:37:59,128] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  9%|▉         | 901/10000 [01:18<22:55,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 204 timesteps with reward=-203.0\n",
      "iter=900\tepsilon=0.436\n",
      "Current score(mean over 3) = -204.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 999/10000 [01:26<11:53, 12.62it/s][2017-03-18 23:38:07,115] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:38:07,119] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 145 timesteps with reward=-144.0\n",
      "Episode finished after 118 timesteps with reward=-117.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:38:07,550] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 10%|█         | 1001/10000 [01:26<22:22,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 151 timesteps with reward=-150.0\n",
      "iter=1000\tepsilon=0.399\n",
      "Current score(mean over 3) = -137.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1099/10000 [01:35<12:18, 12.05it/s][2017-03-18 23:38:16,054] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:38:16,057] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 174 timesteps with reward=-173.0\n",
      "Episode finished after 170 timesteps with reward=-169.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:38:16,555] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 11%|█         | 1101/10000 [01:35<24:11,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 184 timesteps with reward=-183.0\n",
      "iter=1100\tepsilon=0.366\n",
      "Current score(mean over 3) = -175.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1199/10000 [01:44<12:29, 11.74it/s][2017-03-18 23:38:25,234] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:38:25,238] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 132 timesteps with reward=-131.0\n",
      "Episode finished after 117 timesteps with reward=-116.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:38:25,582] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 12%|█▏        | 1201/10000 [01:44<20:25,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 111 timesteps with reward=-110.0\n",
      "iter=1200\tepsilon=0.336\n",
      "Current score(mean over 3) = -119.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1298/10000 [01:53<12:25, 11.67it/s][2017-03-18 23:38:34,301] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:38:34,305] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 115 timesteps with reward=-114.0\n",
      "Episode finished after 111 timesteps with reward=-110.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:38:34,737] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 13%|█▎        | 1301/10000 [01:53<20:31,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 214 timesteps with reward=-213.0\n",
      "iter=1300\tepsilon=0.309\n",
      "Current score(mean over 3) = -145.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1398/10000 [02:03<12:58, 11.05it/s][2017-03-18 23:38:44,201] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:38:44,205] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 214 timesteps with reward=-213.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:38:44,883] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 14%|█▍        | 1400/10000 [02:03<27:28,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 303 timesteps with reward=-302.0\n",
      "Episode finished after 151 timesteps with reward=-150.0\n",
      "iter=1400\tepsilon=0.284\n",
      "Current score(mean over 3) = -221.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1498/10000 [02:13<13:13, 10.72it/s][2017-03-18 23:38:54,342] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:38:54,346] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 141 timesteps with reward=-140.0\n",
      "Episode finished after 206 timesteps with reward=-205.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:38:54,826] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 15%|█▌        | 1501/10000 [02:13<21:05,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 136 timesteps with reward=-135.0\n",
      "iter=1500\tepsilon=0.262\n",
      "Current score(mean over 3) = -160.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1599/10000 [02:24<21:49,  6.41it/s][2017-03-18 23:39:05,983] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:39:05,988] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 94 timesteps with reward=-93.0\n",
      "Episode finished after 120 timesteps with reward=-119.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:39:06,516] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 16%|█▌        | 1600/10000 [02:25<44:07,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 94 timesteps with reward=-93.0\n",
      "iter=1600\tepsilon=0.242\n",
      "Current score(mean over 3) = -101.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1699/10000 [02:37<16:30,  8.38it/s][2017-03-18 23:39:18,406] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:39:18,409] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 141 timesteps with reward=-140.0\n",
      "Episode finished after 143 timesteps with reward=-142.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:39:18,924] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 17%|█▋        | 1701/10000 [02:38<30:36,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 241 timesteps with reward=-240.0\n",
      "iter=1700\tepsilon=0.224\n",
      "Current score(mean over 3) = -174.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1798/10000 [02:47<13:31, 10.11it/s][2017-03-18 23:39:29,062] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:39:29,065] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 191 timesteps with reward=-190.0\n",
      "Episode finished after 135 timesteps with reward=-134.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:39:29,602] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 18%|█▊        | 1801/10000 [02:48<22:16,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 220 timesteps with reward=-219.0\n",
      "iter=1800\tepsilon=0.207\n",
      "Current score(mean over 3) = -181.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1899/10000 [02:58<13:49,  9.76it/s][2017-03-18 23:39:39,936] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:39:39,940] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 100 timesteps with reward=-99.0\n",
      "Episode finished after 113 timesteps with reward=-112.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:39:40,324] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 19%|█▉        | 1901/10000 [02:59<25:31,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 152 timesteps with reward=-151.0\n",
      "iter=1900\tepsilon=0.192\n",
      "Current score(mean over 3) = -120.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1999/10000 [03:09<13:39,  9.76it/s][2017-03-18 23:39:50,771] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:39:50,775] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:39:51,236] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 20%|██        | 2000/10000 [03:10<32:07,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 313 timesteps with reward=-312.0\n",
      "Episode finished after 101 timesteps with reward=-100.0\n",
      "Episode finished after 90 timesteps with reward=-89.0\n",
      "iter=2000\tepsilon=0.179\n",
      "Current score(mean over 3) = -167.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2099/10000 [03:20<13:48,  9.54it/s][2017-03-18 23:40:01,767] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:40:01,771] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 337 timesteps with reward=-336.0\n",
      "Episode finished after 320 timesteps with reward=-319.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:40:02,776] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 21%|██        | 2101/10000 [03:21<42:44,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 415 timesteps with reward=-414.0\n",
      "iter=2100\tepsilon=0.166\n",
      "Current score(mean over 3) = -356.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2199/10000 [03:34<15:32,  8.37it/s][2017-03-18 23:40:15,143] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:40:15,146] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 249 timesteps with reward=-248.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:40:15,870] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 22%|██▏       | 2200/10000 [03:34<44:01,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 289 timesteps with reward=-288.0\n",
      "Episode finished after 218 timesteps with reward=-217.0\n",
      "iter=2200\tepsilon=0.155\n",
      "Current score(mean over 3) = -251.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2299/10000 [03:46<14:31,  8.83it/s][2017-03-18 23:40:27,146] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:40:27,150] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 388 timesteps with reward=-387.0\n",
      "Episode finished after 160 timesteps with reward=-159.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:40:27,891] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 23%|██▎       | 2301/10000 [03:47<35:07,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 251 timesteps with reward=-250.0\n",
      "iter=2300\tepsilon=0.145\n",
      "Current score(mean over 3) = -265.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2399/10000 [03:57<13:32,  9.36it/s][2017-03-18 23:40:38,388] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:40:38,391] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 197 timesteps with reward=-196.0\n",
      "Episode finished after 137 timesteps with reward=-136.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:40:38,902] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 24%|██▍       | 2401/10000 [03:58<27:59,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 215 timesteps with reward=-214.0\n",
      "iter=2400\tepsilon=0.136\n",
      "Current score(mean over 3) = -182.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2499/10000 [04:08<13:04,  9.56it/s][2017-03-18 23:40:49,482] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:40:49,486] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 136 timesteps with reward=-135.0\n",
      "Episode finished after 124 timesteps with reward=-123.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:40:50,182] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 25%|██▌       | 2501/10000 [04:09<32:14,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 500 timesteps with reward=-500.0\n",
      "iter=2500\tepsilon=0.128\n",
      "Current score(mean over 3) = -252.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2599/10000 [04:20<14:30,  8.50it/s][2017-03-18 23:41:01,256] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:41:01,260] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 105 timesteps with reward=-104.0\n",
      "Episode finished after 138 timesteps with reward=-137.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:41:01,705] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 26%|██▌       | 2601/10000 [04:20<26:21,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 135 timesteps with reward=-134.0\n",
      "iter=2600\tepsilon=0.121\n",
      "Current score(mean over 3) = -125.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2699/10000 [04:31<18:34,  6.55it/s][2017-03-18 23:41:12,718] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:41:12,726] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 114 timesteps with reward=-113.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:41:13,230] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 27%|██▋       | 2700/10000 [04:32<39:07,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 89 timesteps with reward=-88.0\n",
      "Episode finished after 83 timesteps with reward=-82.0\n",
      "iter=2700\tepsilon=0.114\n",
      "Current score(mean over 3) = -94.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2799/10000 [04:45<13:44,  8.74it/s][2017-03-18 23:41:26,618] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:41:26,623] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:41:26,925] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 28%|██▊       | 2800/10000 [04:45<25:03,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 125 timesteps with reward=-124.0\n",
      "Episode finished after 94 timesteps with reward=-93.0\n",
      "Episode finished after 89 timesteps with reward=-88.0\n",
      "iter=2800\tepsilon=0.108\n",
      "Current score(mean over 3) = -101.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2899/10000 [04:56<13:00,  9.09it/s][2017-03-18 23:41:37,377] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:41:37,381] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 138 timesteps with reward=-137.0\n",
      "Episode finished after 207 timesteps with reward=-206.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:41:37,866] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 29%|██▉       | 2901/10000 [04:57<25:30,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 168 timesteps with reward=-167.0\n",
      "iter=2900\tepsilon=0.102\n",
      "Current score(mean over 3) = -170.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 2999/10000 [05:07<13:20,  8.75it/s][2017-03-18 23:41:48,405] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:41:48,408] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 124 timesteps with reward=-123.0\n",
      "Episode finished after 132 timesteps with reward=-131.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:41:48,758] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 30%|███       | 3001/10000 [05:07<21:48,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 106 timesteps with reward=-105.0\n",
      "iter=3000\tepsilon=0.097\n",
      "Current score(mean over 3) = -119.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3099/10000 [05:18<12:28,  9.22it/s][2017-03-18 23:41:59,389] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:41:59,393] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:41:59,703] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 31%|███       | 3100/10000 [05:18<23:03,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 112 timesteps with reward=-111.0\n",
      "Episode finished after 111 timesteps with reward=-110.0\n",
      "Episode finished after 87 timesteps with reward=-86.0\n",
      "iter=3100\tepsilon=0.093\n",
      "Current score(mean over 3) = -102.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3199/10000 [05:29<12:14,  9.26it/s][2017-03-18 23:42:10,351] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:42:10,354] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:42:10,720] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 32%|███▏      | 3200/10000 [05:29<24:28,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 180 timesteps with reward=-179.0\n",
      "Episode finished after 115 timesteps with reward=-114.0\n",
      "Episode finished after 98 timesteps with reward=-97.0\n",
      "iter=3200\tepsilon=0.089\n",
      "Current score(mean over 3) = -130.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3299/10000 [05:40<12:17,  9.08it/s][2017-03-18 23:42:21,407] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:42:21,410] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 139 timesteps with reward=-138.0\n",
      "Episode finished after 131 timesteps with reward=-130.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:42:21,763] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 33%|███▎      | 3301/10000 [05:40<21:14,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 112 timesteps with reward=-111.0\n",
      "iter=3300\tepsilon=0.085\n",
      "Current score(mean over 3) = -126.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3399/10000 [05:52<14:31,  7.58it/s][2017-03-18 23:42:33,460] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:42:33,463] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 110 timesteps with reward=-109.0\n",
      "Episode finished after 104 timesteps with reward=-103.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:42:33,953] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 34%|███▍      | 3401/10000 [05:53<25:11,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 108 timesteps with reward=-107.0\n",
      "iter=3400\tepsilon=0.082\n",
      "Current score(mean over 3) = -106.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 3499/10000 [06:05<12:59,  8.34it/s][2017-03-18 23:42:46,758] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:42:46,762] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 104 timesteps with reward=-103.0\n",
      "Episode finished after 191 timesteps with reward=-190.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:42:47,213] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 35%|███▌      | 3501/10000 [06:06<23:43,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 174 timesteps with reward=-173.0\n",
      "iter=3500\tepsilon=0.079\n",
      "Current score(mean over 3) = -155.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3599/10000 [06:20<11:18,  9.44it/s][2017-03-18 23:43:01,872] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:43:01,875] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:43:02,194] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 36%|███▌      | 3600/10000 [06:21<21:49,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 108 timesteps with reward=-107.0\n",
      "Episode finished after 121 timesteps with reward=-120.0\n",
      "Episode finished after 104 timesteps with reward=-103.0\n",
      "iter=3600\tepsilon=0.076\n",
      "Current score(mean over 3) = -110.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3699/10000 [06:32<11:01,  9.52it/s][2017-03-18 23:43:13,322] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:43:13,326] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 75 timesteps with reward=-74.0\n",
      "Episode finished after 92 timesteps with reward=-91.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:43:13,642] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 37%|███▋      | 3701/10000 [06:32<19:08,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 165 timesteps with reward=-164.0\n",
      "iter=3700\tepsilon=0.073\n",
      "Current score(mean over 3) = -109.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3799/10000 [06:43<10:58,  9.42it/s][2017-03-18 23:43:24,119] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:43:24,122] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 122 timesteps with reward=-121.0\n",
      "Episode finished after 180 timesteps with reward=-179.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:43:24,606] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 38%|███▊      | 3801/10000 [06:43<21:32,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 183 timesteps with reward=-182.0\n",
      "iter=3800\tepsilon=0.071\n",
      "Current score(mean over 3) = -160.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3899/10000 [06:54<11:09,  9.11it/s][2017-03-18 23:43:35,248] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:43:35,253] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:43:35,549] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 39%|███▉      | 3900/10000 [06:54<20:34,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 89 timesteps with reward=-88.0\n",
      "Episode finished after 120 timesteps with reward=-119.0\n",
      "Episode finished after 94 timesteps with reward=-93.0\n",
      "iter=3900\tepsilon=0.069\n",
      "Current score(mean over 3) = -100.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 3999/10000 [07:05<10:40,  9.37it/s][2017-03-18 23:43:46,247] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:43:46,252] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 412 timesteps with reward=-411.0\n",
      "Episode finished after 334 timesteps with reward=-333.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:43:47,127] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 40%|████      | 4001/10000 [07:06<29:37,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 248 timesteps with reward=-247.0\n",
      "iter=4000\tepsilon=0.067\n",
      "Current score(mean over 3) = -330.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4099/10000 [07:16<10:06,  9.73it/s][2017-03-18 23:43:57,709] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:43:57,712] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 500 timesteps with reward=-500.0\n",
      "Episode finished after 172 timesteps with reward=-171.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:43:58,561] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 41%|████      | 4101/10000 [07:17<28:12,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 229 timesteps with reward=-228.0\n",
      "iter=4100\tepsilon=0.066\n",
      "Current score(mean over 3) = -299.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4199/10000 [07:28<10:26,  9.26it/s][2017-03-18 23:44:09,365] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:44:09,368] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 228 timesteps with reward=-227.0\n",
      "Episode finished after 136 timesteps with reward=-135.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:44:09,890] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 42%|████▏     | 4201/10000 [07:29<21:27,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 165 timesteps with reward=-164.0\n",
      "iter=4200\tepsilon=0.064\n",
      "Current score(mean over 3) = -175.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4299/10000 [07:39<09:56,  9.56it/s][2017-03-18 23:44:20,569] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:44:20,573] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:44:20,932] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 43%|████▎     | 4300/10000 [07:39<20:01,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 158 timesteps with reward=-157.0\n",
      "Episode finished after 101 timesteps with reward=-100.0\n",
      "Episode finished after 119 timesteps with reward=-118.0\n",
      "iter=4300\tepsilon=0.063\n",
      "Current score(mean over 3) = -125.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4399/10000 [07:50<09:57,  9.37it/s][2017-03-18 23:44:31,790] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:44:31,794] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 170 timesteps with reward=-169.0\n",
      "Episode finished after 190 timesteps with reward=-189.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:44:32,341] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 44%|████▍     | 4401/10000 [07:51<21:34,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 158 timesteps with reward=-157.0\n",
      "iter=4400\tepsilon=0.062\n",
      "Current score(mean over 3) = -171.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 4499/10000 [08:02<10:10,  9.00it/s][2017-03-18 23:44:43,402] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:44:43,404] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 147 timesteps with reward=-146.0\n",
      "Episode finished after 133 timesteps with reward=-132.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:44:43,818] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 45%|████▌     | 4501/10000 [08:02<18:51,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 131 timesteps with reward=-130.0\n",
      "iter=4500\tepsilon=0.061\n",
      "Current score(mean over 3) = -136.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4599/10000 [08:13<09:46,  9.21it/s][2017-03-18 23:44:54,943] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:44:54,947] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 173 timesteps with reward=-172.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:44:55,642] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 46%|████▌     | 4600/10000 [08:14<28:23,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 302 timesteps with reward=-301.0\n",
      "Episode finished after 175 timesteps with reward=-174.0\n",
      "iter=4600\tepsilon=0.060\n",
      "Current score(mean over 3) = -215.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4699/10000 [08:26<18:07,  4.88it/s][2017-03-18 23:45:07,765] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:45:07,768] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 121 timesteps with reward=-120.0\n",
      "Episode finished after 113 timesteps with reward=-112.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:45:08,515] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 47%|████▋     | 4701/10000 [08:27<28:09,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 134 timesteps with reward=-133.0\n",
      "iter=4700\tepsilon=0.059\n",
      "Current score(mean over 3) = -121.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4799/10000 [08:39<10:15,  8.45it/s][2017-03-18 23:45:20,906] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:45:20,909] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 121 timesteps with reward=-120.0\n",
      "Episode finished after 121 timesteps with reward=-120.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:45:21,303] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 48%|████▊     | 4801/10000 [08:40<18:08,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 113 timesteps with reward=-112.0\n",
      "iter=4800\tepsilon=0.058\n",
      "Current score(mean over 3) = -117.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4899/10000 [08:50<08:38,  9.84it/s][2017-03-18 23:45:31,587] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:45:31,591] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:45:31,927] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 49%|████▉     | 4900/10000 [08:50<17:17,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 134 timesteps with reward=-133.0\n",
      "Episode finished after 102 timesteps with reward=-101.0\n",
      "Episode finished after 129 timesteps with reward=-128.0\n",
      "iter=4900\tepsilon=0.057\n",
      "Current score(mean over 3) = -120.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4999/10000 [09:01<09:06,  9.16it/s][2017-03-18 23:45:42,359] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:45:42,362] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 234 timesteps with reward=-233.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:45:43,161] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 50%|█████     | 5000/10000 [09:02<29:14,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 453 timesteps with reward=-452.0\n",
      "Episode finished after 192 timesteps with reward=-191.0\n",
      "iter=5000\tepsilon=0.056\n",
      "Current score(mean over 3) = -292.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 5098/10000 [09:12<09:00,  9.08it/s][2017-03-18 23:45:53,676] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:45:53,681] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:45:54,007] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 51%|█████     | 5100/10000 [09:13<12:47,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 134 timesteps with reward=-133.0\n",
      "Episode finished after 101 timesteps with reward=-100.0\n",
      "Episode finished after 121 timesteps with reward=-120.0\n",
      "iter=5100\tepsilon=0.056\n",
      "Current score(mean over 3) = -117.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 5198/10000 [09:23<08:42,  9.20it/s][2017-03-18 23:46:04,683] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:46:04,689] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 327 timesteps with reward=-326.0\n",
      "Episode finished after 289 timesteps with reward=-288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:46:05,674] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 52%|█████▏    | 5201/10000 [09:24<17:13,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 400 timesteps with reward=-399.0\n",
      "iter=5200\tepsilon=0.055\n",
      "Current score(mean over 3) = -337.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 5299/10000 [09:35<08:19,  9.41it/s][2017-03-18 23:46:16,151] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:46:16,156] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 189 timesteps with reward=-188.0\n",
      "Episode finished after 113 timesteps with reward=-112.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:46:16,670] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 53%|█████▎    | 5301/10000 [09:35<16:42,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 225 timesteps with reward=-224.0\n",
      "iter=5300\tepsilon=0.055\n",
      "Current score(mean over 3) = -174.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5398/10000 [09:45<08:14,  9.31it/s][2017-03-18 23:46:27,064] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:46:27,067] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:46:27,429] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 54%|█████▍    | 5400/10000 [09:46<12:18,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 157 timesteps with reward=-156.0\n",
      "Episode finished after 108 timesteps with reward=-107.0\n",
      "Episode finished after 112 timesteps with reward=-111.0\n",
      "iter=5400\tepsilon=0.054\n",
      "Current score(mean over 3) = -124.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 5499/10000 [09:56<07:46,  9.65it/s][2017-03-18 23:46:37,799] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:46:37,804] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:46:38,115] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 55%|█████▌    | 5500/10000 [09:57<14:56,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 109 timesteps with reward=-108.0\n",
      "Episode finished after 101 timesteps with reward=-100.0\n",
      "Episode finished after 109 timesteps with reward=-108.0\n",
      "iter=5500\tepsilon=0.054\n",
      "Current score(mean over 3) = -105.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5598/10000 [10:07<07:16, 10.09it/s][2017-03-18 23:46:48,282] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:46:48,286] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 123 timesteps with reward=-122.0\n",
      "Episode finished after 83 timesteps with reward=-82.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:46:48,790] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 56%|█████▌    | 5601/10000 [10:07<11:46,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 307 timesteps with reward=-306.0\n",
      "iter=5600\tepsilon=0.054\n",
      "Current score(mean over 3) = -170.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5699/10000 [10:18<07:29,  9.57it/s][2017-03-18 23:46:59,146] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:46:59,149] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 206 timesteps with reward=-205.0\n",
      "Episode finished after 171 timesteps with reward=-170.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:46:59,727] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 57%|█████▋    | 5701/10000 [10:18<16:42,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 250 timesteps with reward=-249.0\n",
      "iter=5700\tepsilon=0.053\n",
      "Current score(mean over 3) = -208.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5799/10000 [10:29<07:12,  9.70it/s][2017-03-18 23:47:10,209] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:47:10,213] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 221 timesteps with reward=-220.0\n",
      "Episode finished after 200 timesteps with reward=-199.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:47:10,839] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 58%|█████▊    | 5801/10000 [10:29<16:52,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 248 timesteps with reward=-247.0\n",
      "iter=5800\tepsilon=0.053\n",
      "Current score(mean over 3) = -222.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5898/10000 [10:40<07:16,  9.40it/s][2017-03-18 23:47:21,498] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:47:21,501] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 406 timesteps with reward=-405.0\n",
      "Episode finished after 500 timesteps with reward=-500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:47:22,604] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 59%|█████▉    | 5901/10000 [10:41<15:20,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 276 timesteps with reward=-275.0\n",
      "iter=5900\tepsilon=0.053\n",
      "Current score(mean over 3) = -393.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 5999/10000 [10:52<06:55,  9.62it/s][2017-03-18 23:47:33,272] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:47:33,275] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 407 timesteps with reward=-406.0\n",
      "Episode finished after 181 timesteps with reward=-180.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:47:34,035] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 60%|██████    | 6001/10000 [10:53<18:07,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 209 timesteps with reward=-208.0\n",
      "iter=6000\tepsilon=0.052\n",
      "Current score(mean over 3) = -264.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 6099/10000 [11:03<07:00,  9.27it/s][2017-03-18 23:47:44,411] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:47:44,415] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 244 timesteps with reward=-243.0\n",
      "Episode finished after 105 timesteps with reward=-104.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:47:44,863] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 61%|██████    | 6101/10000 [11:04<13:42,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 126 timesteps with reward=-125.0\n",
      "iter=6100\tepsilon=0.052\n",
      "Current score(mean over 3) = -157.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 6199/10000 [11:14<06:44,  9.40it/s][2017-03-18 23:47:55,474] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:47:55,477] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 213 timesteps with reward=-212.0\n",
      "Episode finished after 98 timesteps with reward=-97.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:47:55,994] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 62%|██████▏   | 6201/10000 [11:15<13:45,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 215 timesteps with reward=-214.0\n",
      "iter=6200\tepsilon=0.052\n",
      "Current score(mean over 3) = -174.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 6299/10000 [11:25<06:34,  9.39it/s][2017-03-18 23:48:06,522] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:48:06,525] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 294 timesteps with reward=-293.0\n",
      "Episode finished after 140 timesteps with reward=-139.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:48:07,092] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 63%|██████▎   | 6301/10000 [11:26<14:24,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 174 timesteps with reward=-173.0\n",
      "iter=6300\tepsilon=0.052\n",
      "Current score(mean over 3) = -201.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 6398/10000 [11:36<06:22,  9.42it/s][2017-03-18 23:48:17,761] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:48:17,764] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 196 timesteps with reward=-195.0\n",
      "Episode finished after 208 timesteps with reward=-207.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:48:18,340] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 64%|██████▍   | 6401/10000 [11:37<10:11,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 167 timesteps with reward=-166.0\n",
      "iter=6400\tepsilon=0.052\n",
      "Current score(mean over 3) = -189.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 6499/10000 [11:47<06:06,  9.56it/s][2017-03-18 23:48:28,948] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:48:28,951] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 104 timesteps with reward=-103.0\n",
      "Episode finished after 102 timesteps with reward=-101.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:48:29,335] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 65%|██████▌   | 6501/10000 [11:48<11:19,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 173 timesteps with reward=-172.0\n",
      "iter=6500\tepsilon=0.051\n",
      "Current score(mean over 3) = -125.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6599/10000 [11:58<06:01,  9.41it/s][2017-03-18 23:48:40,064] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:48:40,068] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:48:40,356] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 66%|██████▌   | 6600/10000 [11:59<11:07,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 90 timesteps with reward=-89.0\n",
      "Episode finished after 99 timesteps with reward=-98.0\n",
      "Episode finished after 89 timesteps with reward=-88.0\n",
      "iter=6600\tepsilon=0.051\n",
      "Current score(mean over 3) = -91.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6699/10000 [12:09<05:46,  9.54it/s][2017-03-18 23:48:50,845] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:48:50,848] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 408 timesteps with reward=-407.0\n",
      "Episode finished after 208 timesteps with reward=-207.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:48:51,754] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 67%|██████▋   | 6701/10000 [12:10<16:38,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 363 timesteps with reward=-362.0\n",
      "iter=6700\tepsilon=0.051\n",
      "Current score(mean over 3) = -325.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6799/10000 [12:21<05:47,  9.21it/s][2017-03-18 23:49:02,485] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:49:02,488] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 218 timesteps with reward=-217.0\n",
      "Episode finished after 128 timesteps with reward=-127.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:49:02,900] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 68%|██████▊   | 6801/10000 [12:22<10:42,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 114 timesteps with reward=-113.0\n",
      "iter=6800\tepsilon=0.051\n",
      "Current score(mean over 3) = -152.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 6899/10000 [12:32<05:26,  9.49it/s][2017-03-18 23:49:13,431] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:49:13,435] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:49:13,725] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 69%|██████▉   | 6900/10000 [12:32<09:57,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 103 timesteps with reward=-102.0\n",
      "Episode finished after 111 timesteps with reward=-110.0\n",
      "Episode finished after 76 timesteps with reward=-75.0\n",
      "iter=6900\tepsilon=0.051\n",
      "Current score(mean over 3) = -95.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 6999/10000 [12:45<07:40,  6.51it/s][2017-03-18 23:49:26,162] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:49:26,167] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 91 timesteps with reward=-90.0\n",
      "Episode finished after 113 timesteps with reward=-112.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:49:26,647] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 70%|███████   | 7001/10000 [12:45<12:16,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 153 timesteps with reward=-152.0\n",
      "iter=7000\tepsilon=0.051\n",
      "Current score(mean over 3) = -118.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 7099/10000 [12:56<05:05,  9.48it/s][2017-03-18 23:49:37,297] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:49:37,301] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:49:37,542] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 81 timesteps with reward=-80.0\n",
      "Episode finished after 85 timesteps with reward=-84.0\n",
      "Episode finished after 74 timesteps with reward=-73.0\n",
      "iter=7100\tepsilon=0.051\n",
      "Current score(mean over 3) = -79.000\n",
      "You win!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "for i in trange(10000):    \n",
    "    \n",
    "    #play\n",
    "    for _ in range(5):\n",
    "        pool.update(SEQ_LENGTH,append=True)\n",
    "    \n",
    "    #train\n",
    "    train_step()\n",
    "    \n",
    "    #update epsilon\n",
    "    epsilon = 0.05 + 0.95*np.exp(-epoch_counter/1000.)\n",
    "    action_layer.epsilon.set_value(np.float32(epsilon))\n",
    "    \n",
    "    #play a few games for evaluation\n",
    "    if epoch_counter%100==0:\n",
    "        rewards[epoch_counter] = np.mean(pool.evaluate(n_games=3,record_video=False))\n",
    "        print(\"iter=%i\\tepsilon=%.3f\"%(epoch_counter,action_layer.epsilon.get_value(),))\n",
    "        print(\"Current score(mean over %i) = %.3f\"%(3,np.mean(rewards[epoch_counter])))\n",
    "    \n",
    "        if rewards[epoch_counter] >= target_score:\n",
    "            print(\"You win!\")\n",
    "            break\n",
    "\n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:3: FutureWarning: pd.ewm_mean is deprecated for ndarrays and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd1e5fb9dd8>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEACAYAAABGYoqtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKqt0gl6myx8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd1eaca8240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import ewma\n",
    "iters,session_rewards=zip(*sorted(rewards.items(),key=lambda k: k[0]))\n",
    "plt.plot(iters,ewma(np.array(session_rewards),span=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:56:40,683] Making new env: Acrobot-v1\n",
      "[2017-03-18 23:56:40,689] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-18 23:56:40,692] Starting new video recorder writing to /home/golovanov/repo/git/Practical_RL/week4/records/openaigym.video.72.31928.video000000.mp4\n",
      "[2017-03-18 23:56:42,664] Starting new video recorder writing to /home/golovanov/repo/git/Practical_RL/week4/records/openaigym.video.72.31928.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 86 timesteps with reward=-85.0\n",
      "Episode finished after 75 timesteps with reward=-74.0\n",
      "Episode finished after 99 timesteps with reward=-98.0\n",
      "Episode finished after 124 timesteps with reward=-123.0\n",
      "Episode finished after 76 timesteps with reward=-75.0\n",
      "Episode finished after 117 timesteps with reward=-116.0\n",
      "Episode finished after 127 timesteps with reward=-126.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:56:44,977] Starting new video recorder writing to /home/golovanov/repo/git/Practical_RL/week4/records/openaigym.video.72.31928.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 136 timesteps with reward=-135.0\n",
      "Episode finished after 97 timesteps with reward=-96.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-18 23:56:47,166] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 162 timesteps with reward=-161.0\n",
      "average reward: [-85.0, -74.0, -98.0, -123.0, -75.0, -116.0, -126.0, -135.0, -96.0, -161.0]\n"
     ]
    }
   ],
   "source": [
    "final_reward = pool.evaluate(n_games=10,save_path=\"./records\",record_video=True)\n",
    "\n",
    "print(\"average reward:\",final_reward)\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "\n",
    "for video_name in video_names:\n",
    "    HTML(\"\"\"\n",
    "    <video width=\"640\" height=\"480\" controls>\n",
    "      <source src=\"{}\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    \"\"\".format(\"./records/\"+video_name)) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Homework part I (5+ pts)\n",
    "\n",
    "Train a neural network for [`LunarLander-v2`](https://gym.openai.com/envs/LunarLander-v2).\n",
    "* Getting average reward of at least +0 gets you 5 points\n",
    "* Higher reward = more points\n",
    "\n",
    "\n",
    "## Bonus I\n",
    "* Try getting the same [or better] results on Acrobot __(+2 pts)__ or __LunarLander (+3 pts)__ using on-policy methods\n",
    "* You can get n-step q-learning by messing with ```n_steps``` param in the q-learning code above\n",
    "* Note that using large experience replay buffer will slow down on-policy algorithms to almost zero, so it's probably a good idea to use small experience replay buffer with several parallel agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 09:11:50,387] Making new env: LunarLander-v2\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "make_env = lambda: gym.make(\"LunarLander-v2\")\n",
    "\n",
    "env = make_env()\n",
    "env.reset()\n",
    "\n",
    "state_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import rectify\n",
    "\n",
    "observation_layer = InputLayer((None,) + state_shape)\n",
    "layer = DenseLayer(observation_layer, num_units=320, nonlinearity=rectify, W=lasagne.init.HeNormal())\n",
    "layer = DenseLayer(layer, num_units=256, nonlinearity=rectify, W=lasagne.init.HeNormal())\n",
    "layer = DenseLayer(layer, num_units=128, nonlinearity=rectify, W=lasagne.init.HeNormal())\n",
    "qvalues_layer = DenseLayer(layer, num_units=n_actions, nonlinearity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "from agentnet import Agent\n",
    "\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer)\n",
    "\n",
    "agent = Agent(observation_layers=observation_layer, \n",
    "              policy_estimators=qvalues_layer, \n",
    "              action_layers=action_layer)\n",
    "\n",
    "params = lasagne.layers.get_all_params(action_layer, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 10:25:10,443] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,452] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,460] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,465] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,471] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,477] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,481] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,484] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,489] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,493] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,496] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,500] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,505] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,511] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,515] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,519] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,524] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,539] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,546] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:25:10,556] Making new env: LunarLander-v2\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "from agentnet.learning import qlearning\n",
    "\n",
    "SEQ_LENGTH = 7\n",
    "gamma = 0.98\n",
    "n_steps = 1\n",
    "\n",
    "pool = EnvPool(agent, make_env, n_games=20, max_size=int(5 * 1e4))\n",
    "\n",
    "replay = pool.experience_replay.sample_session_batch(1024)\n",
    "qvalues_seq = agent.get_sessions(replay, session_length=SEQ_LENGTH, experience_replay=True)[-1]\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      gamma_or_gammas=gamma,\n",
    "                                                      n_steps=n_steps)\n",
    "\n",
    "#compute mean loss over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()\n",
    "\n",
    "updates = lasagne.updates.adam(loss, params)\n",
    "train_step = theano.function([], loss, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]/usr/local/lib/python3.4/dist-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=1] Warning! Appending sessions to empty or broken pool. Old pool sessions, if any, are disposed.\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n",
      "  0%|          | 199/50000 [00:41<2:41:44,  5.13it/s][2017-03-19 10:26:06,983] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:26:06,987] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-19 10:26:07,329] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  0%|          | 200/50000 [00:41<4:09:16,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 138 timesteps with reward=-170.17923481739177\n",
      "Episode finished after 133 timesteps with reward=-334.13526722231074\n",
      "Episode finished after 74 timesteps with reward=-105.53917802869762\n",
      "iter=200\tepsilon=0.819\n",
      "Current score(mean over 3) = -203.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 399/50000 [01:20<2:46:37,  4.96it/s][2017-03-19 10:26:46,014] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:26:46,018] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-19 10:26:46,329] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  1%|          | 400/50000 [01:20<4:04:49,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 100 timesteps with reward=-83.95091080432175\n",
      "Episode finished after 70 timesteps with reward=-183.3654698443488\n",
      "Episode finished after 139 timesteps with reward=-130.50803985915329\n",
      "iter=400\tepsilon=0.670\n",
      "Current score(mean over 3) = -132.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 599/50000 [02:11<4:26:00,  3.10it/s][2017-03-19 10:27:37,711] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:27:37,715] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 141 timesteps with reward=-104.99001924464997\n",
      "Episode finished after 157 timesteps with reward=-29.71938636853291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 10:27:38,133] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  1%|          | 600/50000 [02:12<6:12:21,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 117 timesteps with reward=-114.69652260417594\n",
      "iter=600\tepsilon=0.549\n",
      "Current score(mean over 3) = -83.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 799/50000 [04:16<9:23:20,  1.46it/s][2017-03-19 10:29:42,257] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:29:42,262] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 232 timesteps with reward=-108.11192298230645\n",
      "Episode finished after 238 timesteps with reward=-163.10103963927784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 10:29:43,701] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  2%|▏         | 800/50000 [04:18<15:15:51,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 274 timesteps with reward=-101.26638547156341\n",
      "iter=800\tepsilon=0.449\n",
      "Current score(mean over 3) = -124.160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 999/50000 [07:00<9:39:47,  1.41it/s][2017-03-19 10:32:27,187] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:32:27,192] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 116 timesteps with reward=-70.40463277346782\n",
      "Episode finished after 1000 timesteps with reward=-54.53962833261677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 10:32:32,892] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  2%|▏         | 1000/50000 [07:07<33:15:44,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 423 timesteps with reward=-41.42215791748836\n",
      "iter=1000\tepsilon=0.368\n",
      "Current score(mean over 3) = -55.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1199/50000 [10:05<12:29:44,  1.08it/s][2017-03-19 10:35:31,458] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:35:31,462] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 230 timesteps with reward=-92.3865271359185\n",
      "Episode finished after 1000 timesteps with reward=4.689624009816125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 10:35:38,161] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  2%|▏         | 1200/50000 [10:12<39:24:22,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 514 timesteps with reward=-268.5509128191722\n",
      "iter=1200\tepsilon=0.301\n",
      "Current score(mean over 3) = -118.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1399/50000 [13:25<12:48:26,  1.05it/s][2017-03-19 10:38:52,335] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:38:52,339] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=39.85463437260588\n",
      "Episode finished after 1000 timesteps with reward=86.51181585819157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 10:39:05,589] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  3%|▎         | 1400/50000 [13:40<66:46:42,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-41.22588123962123\n",
      "iter=1400\tepsilon=0.247\n",
      "Current score(mean over 3) = 28.380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1599/50000 [16:34<13:25:22,  1.00it/s][2017-03-19 10:42:00,530] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:42:00,535] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-33.47362986009936\n",
      "Episode finished after 1000 timesteps with reward=-165.01631318104148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 10:42:12,378] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  3%|▎         | 1600/50000 [16:46<61:12:04,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-60.3368886676344\n",
      "iter=1600\tepsilon=0.202\n",
      "Current score(mean over 3) = -86.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1799/50000 [19:41<12:01:13,  1.11it/s][2017-03-19 10:45:07,445] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:45:07,449] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-182.50125869335142\n",
      "Episode finished after 1000 timesteps with reward=-98.0898469095257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 10:45:19,190] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  4%|▎         | 1800/50000 [19:53<59:30:10,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-128.30793721343844\n",
      "iter=1800\tepsilon=0.165\n",
      "Current score(mean over 3) = -136.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1999/50000 [23:06<11:20:51,  1.18it/s][2017-03-19 10:48:32,635] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:48:32,639] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-66.66093854229078\n",
      "Episode finished after 1000 timesteps with reward=-143.35306111870565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 10:48:45,015] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  4%|▍         | 2000/50000 [23:19<60:42:21,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-43.81153013270185\n",
      "iter=2000\tepsilon=0.135\n",
      "Current score(mean over 3) = -84.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2199/50000 [26:35<15:13:37,  1.15s/it][2017-03-19 10:52:01,775] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:52:01,779] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-145.50467398048968\n",
      "Episode finished after 1000 timesteps with reward=-148.82032576035996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 10:52:15,885] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  4%|▍         | 2200/50000 [26:50<70:22:08,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-126.75344127477763\n",
      "iter=2200\tepsilon=0.111\n",
      "Current score(mean over 3) = -140.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2399/50000 [29:57<11:18:53,  1.17it/s][2017-03-19 10:55:23,459] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:55:23,464] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-93.07384890766242\n",
      "Episode finished after 1000 timesteps with reward=-147.57691805895925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 10:55:36,426] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  5%|▍         | 2400/50000 [30:11<63:04:19,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-44.54940272459027\n",
      "iter=2400\tepsilon=0.091\n",
      "Current score(mean over 3) = -95.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2599/50000 [33:19<9:42:27,  1.36it/s][2017-03-19 10:58:46,030] Making new env: LunarLander-v2\n",
      "[2017-03-19 10:58:46,033] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-50.26522962754735\n",
      "Episode finished after 1000 timesteps with reward=-137.78649400573573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 10:58:51,956] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  5%|▌         | 2600/50000 [33:26<33:05:40,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-106.98961245883358\n",
      "iter=2600\tepsilon=0.074\n",
      "Current score(mean over 3) = -98.347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2799/50000 [36:30<12:33:05,  1.04it/s][2017-03-19 11:01:56,657] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:01:56,661] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 638 timesteps with reward=-219.5022102421185\n",
      "Episode finished after 726 timesteps with reward=-220.70358285063878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:02:04,498] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  6%|▌         | 2800/50000 [36:39<43:03:05,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-115.15662070874983\n",
      "iter=2800\tepsilon=0.061\n",
      "Current score(mean over 3) = -185.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2999/50000 [39:39<15:28:42,  1.19s/it][2017-03-19 11:05:05,704] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:05:05,709] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-60.85881173195088\n",
      "Episode finished after 1000 timesteps with reward=-125.21942705240771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:05:17,355] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  6%|▌         | 3000/50000 [39:51<61:00:05,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-83.9922497106966\n",
      "iter=3000\tepsilon=0.050\n",
      "Current score(mean over 3) = -90.023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 3199/50000 [43:03<10:12:05,  1.27it/s][2017-03-19 11:08:29,993] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:08:29,997] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-54.917886606044156\n",
      "Episode finished after 1000 timesteps with reward=-36.041427448049106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:08:46,113] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  6%|▋         | 3200/50000 [43:20<72:44:28,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-83.61032224625625\n",
      "iter=3200\tepsilon=0.041\n",
      "Current score(mean over 3) = -58.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3399/50000 [46:33<12:12:28,  1.06it/s][2017-03-19 11:11:59,975] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:11:59,979] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-145.18914832603286\n",
      "Episode finished after 148 timesteps with reward=-144.30942048992165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:12:09,634] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  7%|▋         | 3400/50000 [46:44<49:46:23,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-157.50769212673623\n",
      "iter=3400\tepsilon=0.033\n",
      "Current score(mean over 3) = -149.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3599/50000 [49:44<11:23:15,  1.13it/s][2017-03-19 11:15:11,111] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:15:11,115] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-58.81914044967604\n",
      "Episode finished after 1000 timesteps with reward=-103.01765177276376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:15:22,765] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  7%|▋         | 3600/50000 [49:57<55:55:41,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-28.063139041722188\n",
      "iter=3600\tepsilon=0.027\n",
      "Current score(mean over 3) = -63.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3799/50000 [52:54<10:25:12,  1.23it/s][2017-03-19 11:18:21,017] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:18:21,021] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-82.78378200258393\n",
      "Episode finished after 1000 timesteps with reward=-50.10301127375837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:18:33,026] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  8%|▊         | 3800/50000 [53:07<56:20:26,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-62.531556761020575\n",
      "iter=3800\tepsilon=0.022\n",
      "Current score(mean over 3) = -65.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3999/50000 [56:08<11:15:06,  1.14it/s][2017-03-19 11:21:34,919] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:21:34,923] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-93.36054800954933\n",
      "Episode finished after 1000 timesteps with reward=-103.8512104879954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:21:51,755] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  8%|▊         | 4000/50000 [56:26<75:44:26,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-141.41064133791076\n",
      "iter=4000\tepsilon=0.018\n",
      "Current score(mean over 3) = -112.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4199/50000 [59:28<11:19:04,  1.12it/s][2017-03-19 11:24:54,475] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:24:54,481] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=15.988459638269697\n",
      "Episode finished after 1000 timesteps with reward=-92.12364289573677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:25:04,451] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  8%|▊         | 4200/50000 [59:39<48:59:16,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-83.88950068156963\n",
      "iter=4200\tepsilon=0.015\n",
      "Current score(mean over 3) = -53.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 4399/50000 [1:02:32<11:06:21,  1.14it/s][2017-03-19 11:27:58,468] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:27:58,472] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-26.145995113262043\n",
      "Episode finished after 1000 timesteps with reward=-86.0960152359506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:28:17,789] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  9%|▉         | 4400/50000 [1:02:52<84:30:05,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-58.528471059017996\n",
      "iter=4400\tepsilon=0.012\n",
      "Current score(mean over 3) = -56.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 4599/50000 [1:06:04<16:27:19,  1.30s/it][2017-03-19 11:31:30,916] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:31:30,923] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 485 timesteps with reward=158.84823238622147\n",
      "Episode finished after 840 timesteps with reward=103.7714784758849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:31:41,658] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      "  9%|▉         | 4600/50000 [1:06:16<57:42:46,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-114.03509811662649\n",
      "iter=4600\tepsilon=0.010\n",
      "Current score(mean over 3) = 49.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4799/50000 [1:09:33<11:45:11,  1.07it/s][2017-03-19 11:34:59,547] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:34:59,551] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 815 timesteps with reward=133.1023539255119\n",
      "Episode finished after 1000 timesteps with reward=-126.65780300709606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:35:12,487] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 10%|▉         | 4800/50000 [1:09:47<60:13:22,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-97.86623359839756\n",
      "iter=4800\tepsilon=0.008\n",
      "Current score(mean over 3) = -30.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4999/50000 [1:12:46<12:29:10,  1.00it/s][2017-03-19 11:38:13,193] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:38:13,198] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-101.8641684773728\n",
      "Episode finished after 1000 timesteps with reward=-104.64165703817872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:38:28,011] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 10%|█         | 5000/50000 [1:13:02<68:17:23,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 316 timesteps with reward=162.56063926190248\n",
      "iter=5000\tepsilon=0.007\n",
      "Current score(mean over 3) = -14.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5199/50000 [1:16:06<8:52:33,  1.40it/s][2017-03-19 11:41:33,053] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:41:33,057] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-140.73605887620357\n",
      "Episode finished after 1000 timesteps with reward=-86.78269004241501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:41:43,716] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 10%|█         | 5200/50000 [1:16:18<48:58:37,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-100.34349875596459\n",
      "iter=5200\tepsilon=0.006\n",
      "Current score(mean over 3) = -109.287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 5399/50000 [1:18:56<9:06:09,  1.36it/s][2017-03-19 11:44:22,672] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:44:22,676] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 459 timesteps with reward=173.56765735649773\n",
      "Episode finished after 1000 timesteps with reward=-101.2857417015861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:44:30,554] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 11%|█         | 5400/50000 [1:19:05<38:32:30,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-108.87098051428994\n",
      "iter=5400\tepsilon=0.005\n",
      "Current score(mean over 3) = -12.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 5599/50000 [1:21:29<9:03:06,  1.36it/s][2017-03-19 11:46:55,419] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:46:55,424] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 370 timesteps with reward=188.38492388038762\n",
      "Episode finished after 397 timesteps with reward=211.1171135986777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:46:57,768] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 11%|█         | 5600/50000 [1:21:32<17:41:38,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 659 timesteps with reward=141.23378620548485\n",
      "iter=5600\tepsilon=0.004\n",
      "Current score(mean over 3) = 180.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5799/50000 [1:23:24<8:02:18,  1.53it/s][2017-03-19 11:48:50,659] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:48:50,662] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-88.32691317821494\n",
      "Episode finished after 215 timesteps with reward=11.647168348795361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:48:55,184] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 12%|█▏        | 5800/50000 [1:23:29<24:41:30,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-152.86354058898098\n",
      "iter=5800\tepsilon=0.003\n",
      "Current score(mean over 3) = -76.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5999/50000 [1:25:44<8:47:37,  1.39it/s][2017-03-19 11:51:10,859] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:51:10,864] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-151.00030942225007\n",
      "Episode finished after 1000 timesteps with reward=-133.59535690020215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:51:18,317] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 12%|█▏        | 6000/50000 [1:25:52<35:42:31,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 229 timesteps with reward=-232.221089061246\n",
      "iter=6000\tepsilon=0.002\n",
      "Current score(mean over 3) = -172.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6199/50000 [1:27:57<10:17:13,  1.18it/s][2017-03-19 11:53:23,377] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:53:23,381] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-86.72815778915906\n",
      "Episode finished after 1000 timesteps with reward=57.18434584315841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:53:28,428] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 12%|█▏        | 6200/50000 [1:28:03<28:32:10,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 596 timesteps with reward=142.97330744963298\n",
      "iter=6200\tepsilon=0.002\n",
      "Current score(mean over 3) = 37.810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 6399/50000 [1:29:49<5:12:32,  2.33it/s][2017-03-19 11:55:15,071] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:55:15,075] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-256.7159679284065\n",
      "Episode finished after 1000 timesteps with reward=-174.22588143177092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:55:22,086] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 13%|█▎        | 6400/50000 [1:29:56<30:31:06,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-105.81485133821405\n",
      "iter=6400\tepsilon=0.002\n",
      "Current score(mean over 3) = -178.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 6599/50000 [1:31:46<5:17:44,  2.28it/s][2017-03-19 11:57:12,565] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:57:12,569] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 264 timesteps with reward=237.50540145548808\n",
      "Episode finished after 264 timesteps with reward=205.89898822047553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:57:13,530] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 13%|█▎        | 6600/50000 [1:31:48<8:39:49,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 245 timesteps with reward=225.17558189313095\n",
      "iter=6600\tepsilon=0.001\n",
      "Current score(mean over 3) = 222.860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 6799/50000 [1:33:22<5:11:12,  2.31it/s][2017-03-19 11:58:48,521] Making new env: LunarLander-v2\n",
      "[2017-03-19 11:58:48,525] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 235 timesteps with reward=199.48733247913583\n",
      "Episode finished after 391 timesteps with reward=227.61862965407843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 11:58:49,573] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 14%|█▎        | 6800/50000 [1:33:24<8:54:58,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 236 timesteps with reward=236.51611676633445\n",
      "iter=6800\tepsilon=0.001\n",
      "Current score(mean over 3) = 221.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 6999/50000 [1:34:55<3:59:39,  2.99it/s][2017-03-19 12:00:21,099] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:00:21,103] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 240 timesteps with reward=200.6860137073555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:00:21,970] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 14%|█▍        | 7000/50000 [1:34:56<7:00:25,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 381 timesteps with reward=227.3213528259944\n",
      "Episode finished after 219 timesteps with reward=199.20716968645579\n",
      "iter=7000\tepsilon=0.001\n",
      "Current score(mean over 3) = 209.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7199/50000 [1:36:23<3:49:52,  3.10it/s][2017-03-19 12:01:49,266] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:01:49,270] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 200 timesteps with reward=194.84900556597222\n",
      "Episode finished after 229 timesteps with reward=200.7032384455972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:01:50,071] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 14%|█▍        | 7200/50000 [1:36:24<6:41:24,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 228 timesteps with reward=209.100790858531\n",
      "iter=7200\tepsilon=0.001\n",
      "Current score(mean over 3) = 201.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 7399/50000 [1:37:34<5:26:54,  2.17it/s][2017-03-19 12:03:00,196] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:03:00,199] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 299 timesteps with reward=226.98715090812829\n",
      "Episode finished after 260 timesteps with reward=232.8765839983575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:03:01,294] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 15%|█▍        | 7400/50000 [1:37:35<9:25:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 325 timesteps with reward=208.92984068912722\n",
      "iter=7400\tepsilon=0.001\n",
      "Current score(mean over 3) = 222.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 7599/50000 [1:38:53<5:16:23,  2.23it/s][2017-03-19 12:04:19,710] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:04:19,713] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 478 timesteps with reward=250.16642004539474\n",
      "Episode finished after 194 timesteps with reward=179.3358307130244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:04:20,652] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 15%|█▌        | 7600/50000 [1:38:55<8:03:23,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 125 timesteps with reward=202.90919059589137\n",
      "iter=7600\tepsilon=0.001\n",
      "Current score(mean over 3) = 210.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 7799/50000 [1:40:21<3:43:09,  3.15it/s][2017-03-19 12:05:47,676] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:05:47,680] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-139.5521460832751\n",
      "Episode finished after 370 timesteps with reward=171.84033629590985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:05:50,605] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 16%|█▌        | 7800/50000 [1:40:25<14:02:56,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 545 timesteps with reward=197.33521454653442\n",
      "iter=7800\tepsilon=0.000\n",
      "Current score(mean over 3) = 76.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 7999/50000 [1:41:41<4:44:39,  2.46it/s][2017-03-19 12:07:07,213] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:07:07,217] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 287 timesteps with reward=230.24666018103397\n",
      "Episode finished after 156 timesteps with reward=209.30828949880296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:07:07,951] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 16%|█▌        | 8000/50000 [1:41:42<7:18:25,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 221 timesteps with reward=240.5296446157113\n",
      "iter=8000\tepsilon=0.000\n",
      "Current score(mean over 3) = 226.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 8199/50000 [1:42:46<3:38:21,  3.19it/s][2017-03-19 12:08:11,756] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:08:11,760] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 243 timesteps with reward=224.17873579195532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:08:12,847] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 16%|█▋        | 8200/50000 [1:42:47<7:22:57,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 406 timesteps with reward=223.98548788281983\n",
      "Episode finished after 197 timesteps with reward=230.4469060766768\n",
      "iter=8200\tepsilon=0.000\n",
      "Current score(mean over 3) = 226.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 8399/50000 [1:43:55<3:32:11,  3.27it/s][2017-03-19 12:09:21,023] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:09:21,027] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 247 timesteps with reward=199.2872724158562\n",
      "Episode finished after 235 timesteps with reward=240.83051911852516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:09:21,715] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 17%|█▋        | 8400/50000 [1:43:56<6:00:28,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 204 timesteps with reward=203.76426821232343\n",
      "iter=8400\tepsilon=0.000\n",
      "Current score(mean over 3) = 214.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 8599/50000 [1:45:20<3:14:00,  3.56it/s][2017-03-19 12:10:46,286] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:10:46,290] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 321 timesteps with reward=218.25556593219738\n",
      "Episode finished after 375 timesteps with reward=185.54327517438855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:10:47,592] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 17%|█▋        | 8600/50000 [1:45:22<7:46:14,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 366 timesteps with reward=203.7551625462669\n",
      "iter=8600\tepsilon=0.000\n",
      "Current score(mean over 3) = 202.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 8799/50000 [1:46:37<3:37:05,  3.16it/s][2017-03-19 12:12:03,294] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:12:03,297] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 215 timesteps with reward=242.1176792895741\n",
      "Episode finished after 265 timesteps with reward=208.45261071458427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:12:04,168] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 18%|█▊        | 8800/50000 [1:46:38<6:34:31,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 217 timesteps with reward=235.2807746731774\n",
      "iter=8800\tepsilon=0.000\n",
      "Current score(mean over 3) = 228.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 8999/50000 [1:47:49<5:02:48,  2.26it/s][2017-03-19 12:13:15,711] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:13:15,714] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 242 timesteps with reward=250.05790469737266\n",
      "Episode finished after 190 timesteps with reward=254.15483482093396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:13:16,396] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 18%|█▊        | 9000/50000 [1:47:50<7:25:30,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 210 timesteps with reward=205.10475269806884\n",
      "iter=9000\tepsilon=0.000\n",
      "Current score(mean over 3) = 236.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9199/50000 [1:49:03<3:53:26,  2.91it/s][2017-03-19 12:14:29,246] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:14:29,250] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 248 timesteps with reward=217.63867178973834\n",
      "Episode finished after 286 timesteps with reward=197.44091782310875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:14:30,364] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 18%|█▊        | 9200/50000 [1:49:04<7:44:29,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 306 timesteps with reward=243.91931470442856\n",
      "iter=9200\tepsilon=0.000\n",
      "Current score(mean over 3) = 219.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 9399/50000 [1:50:17<4:04:26,  2.77it/s][2017-03-19 12:15:42,794] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:15:42,797] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-03-19 12:15:43,043] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 19%|█▉        | 9400/50000 [1:50:17<4:35:47,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 73 timesteps with reward=-37.46390076097744\n",
      "Episode finished after 71 timesteps with reward=-59.591626576244565\n",
      "Episode finished after 101 timesteps with reward=-21.378070057827102\n",
      "iter=9400\tepsilon=0.000\n",
      "Current score(mean over 3) = -39.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 9599/50000 [1:51:53<4:29:07,  2.50it/s][2017-03-19 12:17:19,698] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:17:19,702] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 224 timesteps with reward=242.66629673899692\n",
      "Episode finished after 228 timesteps with reward=225.43151084993153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:17:20,541] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 19%|█▉        | 9600/50000 [1:51:55<7:23:43,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 267 timesteps with reward=191.74729278928748\n",
      "iter=9600\tepsilon=0.000\n",
      "Current score(mean over 3) = 219.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 9799/50000 [1:53:20<3:30:48,  3.18it/s][2017-03-19 12:18:45,813] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:18:45,817] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 271 timesteps with reward=238.57312251940903\n",
      "Episode finished after 187 timesteps with reward=198.48141826680816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:18:47,736] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 20%|█▉        | 9800/50000 [1:53:22<10:00:41,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=136.05671834316718\n",
      "iter=9800\tepsilon=0.000\n",
      "Current score(mean over 3) = 191.037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 9999/50000 [1:54:29<3:45:54,  2.95it/s][2017-03-19 12:19:55,542] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:19:55,546] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 215 timesteps with reward=213.6162104879262\n",
      "Episode finished after 197 timesteps with reward=218.14019340774416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:19:56,269] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 20%|██        | 10000/50000 [1:54:30<6:10:31,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 234 timesteps with reward=184.3217058891774\n",
      "iter=10000\tepsilon=0.000\n",
      "Current score(mean over 3) = 205.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10199/50000 [1:55:40<4:06:53,  2.69it/s][2017-03-19 12:21:05,816] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:21:05,820] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=129.4772585092444\n",
      "Episode finished after 138 timesteps with reward=240.95465022313354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:21:08,423] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 20%|██        | 10200/50000 [1:55:43<12:43:05,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=110.0439054449575\n",
      "iter=10200\tepsilon=0.000\n",
      "Current score(mean over 3) = 160.159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 10399/50000 [1:56:52<3:21:15,  3.28it/s][2017-03-19 12:22:18,672] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:22:18,676] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 221 timesteps with reward=235.71866482650267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:22:20,303] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 21%|██        | 10400/50000 [1:56:54<8:42:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=92.7198886154706\n",
      "Episode finished after 184 timesteps with reward=218.99436639826877\n",
      "iter=10400\tepsilon=0.000\n",
      "Current score(mean over 3) = 182.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 10599/50000 [1:58:02<3:47:38,  2.88it/s][2017-03-19 12:23:28,047] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:23:28,051] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 218 timesteps with reward=192.33744177985128\n",
      "Episode finished after 195 timesteps with reward=257.3032325661112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:23:28,713] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 21%|██        | 10600/50000 [1:58:03<5:50:26,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 238 timesteps with reward=243.7034739521801\n",
      "iter=10600\tepsilon=0.000\n",
      "Current score(mean over 3) = 231.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 10799/50000 [1:59:05<3:34:42,  3.04it/s][2017-03-19 12:24:31,753] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:24:31,756] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 526 timesteps with reward=154.80666596397703\n",
      "Episode finished after 508 timesteps with reward=158.59700279300472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:24:34,432] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 22%|██▏       | 10800/50000 [1:59:09<12:21:39,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 628 timesteps with reward=155.14012461014335\n",
      "iter=10800\tepsilon=0.000\n",
      "Current score(mean over 3) = 156.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 10999/50000 [2:00:17<4:09:38,  2.60it/s][2017-03-19 12:25:43,260] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:25:43,264] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 167 timesteps with reward=194.1961314592427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:25:44,153] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 22%|██▏       | 11000/50000 [2:00:18<7:00:48,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 410 timesteps with reward=-43.52502657740338\n",
      "Episode finished after 146 timesteps with reward=237.9869216561785\n",
      "iter=11000\tepsilon=0.000\n",
      "Current score(mean over 3) = 129.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11199/50000 [2:01:21<3:14:42,  3.32it/s][2017-03-19 12:26:46,907] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:26:46,910] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 459 timesteps with reward=154.454918294388\n",
      "Episode finished after 431 timesteps with reward=209.29439191153887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:26:48,956] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 22%|██▏       | 11200/50000 [2:01:23<9:52:38,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 465 timesteps with reward=169.24487450660394\n",
      "iter=11200\tepsilon=0.000\n",
      "Current score(mean over 3) = 177.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 11399/50000 [2:02:34<3:15:49,  3.29it/s][2017-03-19 12:28:00,322] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:28:00,326] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 167 timesteps with reward=232.2226739125845\n",
      "Episode finished after 169 timesteps with reward=221.70620836448663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:28:01,056] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 23%|██▎       | 11400/50000 [2:02:35<5:42:10,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 260 timesteps with reward=163.6687139971591\n",
      "iter=11400\tepsilon=0.000\n",
      "Current score(mean over 3) = 205.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 11599/50000 [2:03:50<4:57:38,  2.15it/s][2017-03-19 12:29:16,537] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:29:16,541] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 168 timesteps with reward=207.41104715273997\n",
      "Episode finished after 156 timesteps with reward=222.33383362881722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:29:17,109] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 23%|██▎       | 11600/50000 [2:03:51<6:45:36,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 225 timesteps with reward=250.29179669380747\n",
      "iter=11600\tepsilon=0.000\n",
      "Current score(mean over 3) = 226.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 11799/50000 [2:05:04<4:04:43,  2.60it/s][2017-03-19 12:30:29,866] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:30:29,870] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 234 timesteps with reward=235.11478183693495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:30:30,541] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 24%|██▎       | 11800/50000 [2:05:05<6:14:53,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 224 timesteps with reward=234.5365207464682\n",
      "Episode finished after 188 timesteps with reward=210.74173632370324\n",
      "iter=11800\tepsilon=0.000\n",
      "Current score(mean over 3) = 226.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 11999/50000 [2:06:08<3:14:05,  3.26it/s][2017-03-19 12:31:33,726] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:31:33,729] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 246 timesteps with reward=205.2017796093204\n",
      "Episode finished after 1000 timesteps with reward=87.74784885093504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:31:35,966] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 24%|██▍       | 12000/50000 [2:06:10<10:19:53,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 210 timesteps with reward=202.11370588559507\n",
      "iter=12000\tepsilon=0.000\n",
      "Current score(mean over 3) = 165.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12199/50000 [2:07:18<4:03:19,  2.59it/s][2017-03-19 12:32:44,672] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:32:44,676] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 139 timesteps with reward=232.70469571050464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:32:45,306] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 24%|██▍       | 12200/50000 [2:07:19<6:08:26,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 219 timesteps with reward=217.32248378351665\n",
      "Episode finished after 185 timesteps with reward=228.95680564865518\n",
      "iter=12200\tepsilon=0.000\n",
      "Current score(mean over 3) = 226.328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 12399/50000 [2:08:29<3:46:31,  2.77it/s][2017-03-19 12:33:55,387] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:33:55,391] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=32.98998278112158\n",
      "Episode finished after 645 timesteps with reward=92.26652779404895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:34:00,326] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 25%|██▍       | 12400/50000 [2:08:34<19:27:41,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 909 timesteps with reward=139.07915073947248\n",
      "iter=12400\tepsilon=0.000\n",
      "Current score(mean over 3) = 88.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 12599/50000 [2:10:12<5:46:59,  1.80it/s][2017-03-19 12:35:38,388] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:35:38,392] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-152.98992981026788\n",
      "Episode finished after 199 timesteps with reward=199.7098149668782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:35:41,104] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 25%|██▌       | 12600/50000 [2:10:15<14:25:11,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 208 timesteps with reward=217.87240888504442\n",
      "iter=12600\tepsilon=0.000\n",
      "Current score(mean over 3) = 88.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 12799/50000 [2:11:49<3:45:01,  2.76it/s][2017-03-19 12:37:15,682] Making new env: LunarLander-v2\n",
      "[2017-03-19 12:37:15,685] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 267 timesteps with reward=189.87969278753314\n",
      "Episode finished after 294 timesteps with reward=192.33502427341296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-19 12:37:16,751] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/golovanov/repo/git/Practical_RL/week4/records')\n",
      " 26%|██▌       | 12800/50000 [2:11:51<7:07:12,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 330 timesteps with reward=201.83960092192973\n",
      "iter=12800\tepsilon=0.000\n",
      "Current score(mean over 3) = 194.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 12947/50000 [2:12:42<4:29:47,  2.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-379c44b4ed37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#play\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/agentnet/experiments/openai_gym/pool.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, n_steps, append, max_size, add_last_observation, preprocess)\u001b[0m\n\u001b[1;32m    204\u001b[0m             self.experience_replay.append_sessions(observation_tensor, action_tensor, reward_tensor,\n\u001b[1;32m    205\u001b[0m                                                    \u001b[0mis_alive_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreceding_memory_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                                                    max_pool_size=max_size or self.max_size)\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     def evaluate(self, n_games=1, save_path=\"./records\", use_monitor=True, record_video=True, verbose=True,\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/agentnet/environment/session_pool.py\u001b[0m in \u001b[0;36mappend_sessions\u001b[0;34m(self, observation_sequences, action_sequences, reward_seq, is_alive, prev_memories, max_pool_size)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m#load everything into the environmnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_sessions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_alive_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprev_memory_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/agentnet/environment/session_pool.py\u001b[0m in \u001b[0;36mload_sessions\u001b[0;34m(self, observation_sequences, action_sequences, reward_seq, is_alive, prev_memories)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mset_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mset_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_alive\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/agentnet/utils/shared.py\u001b[0m in \u001b[0;36mset_shared\u001b[0;34m(var, value)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mset_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mval_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "epoch_counter = 1\n",
    "rewards = {}\n",
    "\n",
    "for i in trange(50000):    \n",
    "    \n",
    "    #update epsilon\n",
    "    epsilon = 1.0 * np.exp(-epoch_counter / 1000.)\n",
    "    action_layer.epsilon.set_value(np.float32(epsilon))\n",
    "    \n",
    "    #play\n",
    "    for _ in range(3):\n",
    "        pool.update(SEQ_LENGTH, append=True)\n",
    "    \n",
    "    #train\n",
    "    train_step()\n",
    "    \n",
    "    #play a few games for evaluation\n",
    "    if epoch_counter % 200 == 0:\n",
    "        rewards[epoch_counter] = np.mean(pool.evaluate(n_games=3, record_video=False))\n",
    "        print(\"iter=%i\\tepsilon=%.3f\"%(epoch_counter,action_layer.epsilon.get_value(),))\n",
    "        print(\"Current score(mean over %i) = %.3f\"%(3, np.mean(rewards[epoch_counter])))\n",
    "    \n",
    "    epoch_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
